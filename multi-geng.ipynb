{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 08:13:00.027127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 08:13:00.947058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-28 08:13:02 INFO [root] [<module>:23] - PATH:/data4/conda_envs/g2/bin:/usr/local/cuda-11.6/bin:/home/beihang/.vscode-server/bin/8b3775030ed1a69b13e4f4c628c612102e30a681/bin/remote-cli:/data4/conda_envs/g2/bin:/usr/local/cuda-10.1/bin:/sbin:/usr/bin:/home/beihang/anaconda3/bin:/home/beihang/anaconda3/condabin:/bin:/usr/bin:/usr/local/bin:/usr/local/cuda-10.1/bin:/home/beihang/anaconda3/bin:/bin:/usr/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/cuda-10.1/bin:/home/beihang/anaconda3/bin:/bin:/usr/bin:/usr/local/cuda/bin:/snap/bin\n",
      "CUDA_HOME:/usr/local/cuda-11.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# from aeon.datasets.tsc_data_lists import multivariate_equal_length\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time \n",
    "# from utils import geng\n",
    "import logconfig\n",
    "import geng\n",
    "import torch\n",
    "import logging\n",
    "# # 修改一个已存在的环境变量\n",
    "# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']\n",
    "# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']\n",
    "# 使用设置好的环境变量\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"7\"\n",
    "logconfig.setup_logging(dir=\"./\")\n",
    "logging.info(f\"PATH:{os.environ['PATH']}\\nCUDA_HOME:{os.environ['CUDA_HOME']}\")\n",
    "# dataset_name = \"170Kailuan-relu-5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aeon.datasets import load_classification\n",
    "# import numpy as np\n",
    "# dataset_name = \"Libras\"\n",
    "# archive_name=\"MTS\"\n",
    "# X, Y,meta_data = load_classification(dataset_name,return_metadata=True)\n",
    "# X_reshaped = np.transpose(X, (0, 2, 1))\n",
    "# X = X_reshaped\n",
    "# nb_classes = len(np.unique(Y, axis=0))\n",
    "# nb_classes,X.shape,Y.shape,np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Kailuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140088, 6), (39711, 8), (170, 35))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "archive_name=\"MTS\"\n",
    "time_series1 = pd.read_csv(\"./combined_sheets.csv\")\n",
    "time_series2 = pd.read_csv(\"./combined_sheets2.csv\")\n",
    "meta_data = pd.read_csv(\"./combinde170_info.csv\")\n",
    "time_series1.shape,time_series2.shape,meta_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sleepstate</th>\n",
       "      <th>Breath</th>\n",
       "      <th>Heartrate</th>\n",
       "      <th>Movement</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-02 16:35:25</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-02 16:36:25</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-02 16:37:25</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-02 16:38:25</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-02 16:39:25</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39706</th>\n",
       "      <td>2023-12-22 22:58:00</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39707</th>\n",
       "      <td>2023-12-22 22:59:00</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39708</th>\n",
       "      <td>2023-12-22 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39709</th>\n",
       "      <td>2023-12-22 23:01:00</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39710</th>\n",
       "      <td>2023-12-22 23:02:00</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179799 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp  Sleepstate  Breath  Heartrate  Movement  Source\n",
       "0      2021-07-02 16:35:25           4      16         78         2       1\n",
       "1      2021-07-02 16:36:25           4      16         76         0       1\n",
       "2      2021-07-02 16:37:25           4      16         74         0       1\n",
       "3      2021-07-02 16:38:25           4      16         74         0       1\n",
       "4      2021-07-02 16:39:25           4      16         73         0       1\n",
       "...                    ...         ...     ...        ...       ...     ...\n",
       "39706  2023-12-22 22:58:00           4      17         86         0     170\n",
       "39707  2023-12-22 22:59:00           2      17         87         0     170\n",
       "39708  2023-12-22 23:00:00           4      17         87         0     170\n",
       "39709  2023-12-22 23:01:00           4      18         88         0     170\n",
       "39710  2023-12-22 23:02:00           4      19         88         0     170\n",
       "\n",
       "[179799 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series2 = time_series2.drop(['SystolicPressure','DiastolicPressure'],axis=1)\n",
    "time_series = pd.concat([time_series1, time_series2], axis=0)\n",
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movement全变成1 二值化\n",
    "# time_series['Movement'] = np.where(time_series['Movement'] != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造每个source的二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = time_series.groupby('Source')\n",
    "\n",
    "# 提取特征列\n",
    "features = [ 'Breath', 'Heartrate']\n",
    "\n",
    "# # 将每个组转换为二维数组并堆叠\n",
    "# three_dim_array = np.array([group[features].values for _, group in grouped])\n",
    "\n",
    "# three_dim_array.shape # 显示三维数组的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement 处理\n",
    "- Movement 取消： 只有fold3有提升 其他4个fold下降\n",
    "- Movement 全部+1 不行 都有下降\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_groupby = time_series.groupby('Source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看movement的分布\n",
    "# movement_stac=[{}]\n",
    "# for i in range(1,136):\n",
    "#     logging.info(i)\n",
    "#     keys, vals = np.unique(time_groupby.get_group(int(i))[\"Movement\"].values,return_counts=True)\n",
    "#     result_dict = dict(zip(keys, vals))\n",
    "#     logging.info(result_dict)\n",
    "#     movement_stac.append(result_dict)\n",
    "\n",
    "# # movement_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充 截断 时间序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充/截断 构造数据集(去掉过少的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial block \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 929, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 668, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 373, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_53192/3991018010.py\", line 7, in <module>\n",
      "    logging.info(\"valid sources:\", valid_sources, \"\\nobsolete sources:\", obsolete_sources, \"\\n len of obsoletes:\",filtered_time_steps_per_source[obsolete_sources])\n",
      "Message: 'valid sources:'\n",
      "Arguments: (Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
      "       ...\n",
      "       161, 162, 163, 164, 165, 166, 167, 168, 169, 170],\n",
      "      dtype='int64', name='Source', length=164), '\\nobsolete sources:', Index([21, 26, 74, 75, 107, 130], dtype='int64', name='Source'), '\\n len of obsoletes:', Source\n",
      "21     148\n",
      "26     251\n",
      "74     193\n",
      "75     150\n",
      "107    415\n",
      "130    188\n",
      "dtype: int64)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 929, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 668, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/logging/__init__.py\", line 373, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/data4/conda_envs/g2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_53192/3991018010.py\", line 7, in <module>\n",
      "    logging.info(\"valid sources:\", valid_sources, \"\\nobsolete sources:\", obsolete_sources, \"\\n len of obsoletes:\",filtered_time_steps_per_source[obsolete_sources])\n",
      "Message: 'valid sources:'\n",
      "Arguments: (Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
      "       ...\n",
      "       161, 162, 163, 164, 165, 166, 167, 168, 169, 170],\n",
      "      dtype='int64', name='Source', length=164), '\\nobsolete sources:', Index([21, 26, 74, 75, 107, 130], dtype='int64', name='Source'), '\\n len of obsoletes:', Source\n",
      "21     148\n",
      "26     251\n",
      "74     193\n",
      "75     150\n",
      "107    415\n",
      "130    188\n",
      "dtype: int64)\n",
      "2024-01-28 08:13:03 INFO [root] [<module>:17] - \n",
      " average_time_steps:1088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(164, 1088, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新计算每个样例的时间步数（考虑到了数据过滤）\n",
    "filtered_time_steps_per_source = time_series.groupby('Source').size()\n",
    "\n",
    "# 重新筛选出有效的 Source 过滤掉过少的\n",
    "valid_sources = filtered_time_steps_per_source[filtered_time_steps_per_source > 500].index\n",
    "obsolete_sources = filtered_time_steps_per_source[filtered_time_steps_per_source <= 500].index\n",
    "logging.info(\"valid sources:\", valid_sources, \"\\nobsolete sources:\", obsolete_sources, \"\\n len of obsoletes:\",filtered_time_steps_per_source[obsolete_sources])\n",
    "# 重新获取有效的数据\n",
    "valid_filtered_time_series = time_series[time_series['Source'].isin(valid_sources)]\n",
    "\n",
    "# 重新分组\n",
    "valid_filtered_grouped = valid_filtered_time_series.groupby('Source')\n",
    "\n",
    "# 重新计算平均时间步数（此时应该没有 NaN 值）\n",
    "average_time_steps = int(valid_filtered_grouped.size().mean())\n",
    "\n",
    "logging.info(f\"\\n average_time_steps:{average_time_steps}\")\n",
    "\n",
    "# 初始化新的三维数组（考虑到了有效的样例数）\n",
    "valid_sources_count = len(valid_sources)\n",
    "three_dim_array_valid = np.zeros((valid_sources_count, average_time_steps, len(features)))\n",
    "\n",
    "# 填充新的三维数组\n",
    "for i, (source, group) in enumerate(valid_filtered_grouped):\n",
    "    data = group[features].values\n",
    "    current_steps = data.shape[0]\n",
    "    if current_steps < average_time_steps:\n",
    "        fill_values = {\n",
    "            'Breath': group['Breath'].mean(),\n",
    "            'Heartrate': group['Heartrate'].mean(),\n",
    "        }\n",
    "        fill_array = np.array([[fill_values[feature] for feature in features]] * (average_time_steps - current_steps))\n",
    "        full_data = np.vstack(( fill_array,data))\n",
    "    else:\n",
    "        # 调整为截取较后面的元素\n",
    "        full_data = data[current_steps-average_time_steps:, :]\n",
    "    # logging.info(f\"source:{source},current_steps:{current_steps}, full_data shape:{full_data.shape}\")\n",
    "    three_dim_array_valid[i, :, :] = full_data\n",
    "\n",
    "\n",
    "final_data = three_dim_array_valid\n",
    "\n",
    "# 进行数据标准化\n",
    "final_data = geng.standard_scaler_total(final_data)\n",
    "\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签构造\n",
    "- 意识状态\n",
    "- GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "       ...\n",
       "       161, 162, 163, 164, 165, 166, 167, 168, 169, 170],\n",
       "      dtype='int64', name='Source', length=164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "        2, 2, 2, 1, 1, 1, 1, 1, 2, 1]),\n",
       " (164,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = meta_data[\"意识状态\"].values\n",
    "\n",
    "valid_sources = valid_sources-1\n",
    "labels = [labels[i] for i in range(len(labels)) if i in valid_sources]\n",
    "# labels = [1 if x == 2 else x for x in labels]\n",
    "nb_classes = len(np.unique(labels, axis=0))\n",
    "labels = np.array(labels)\n",
    "labels, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (填充/截断)构造数据集 原本版 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# average_time_steps = int(grouped.apply(lambda x: x.shape[0]).mean())\n",
    "\n",
    "# # 初始化三维数组\n",
    "# features = ['Sleepstate', 'Breath', 'Heartrate', 'Movement']\n",
    "# three_dim_array = np.zeros((135, average_time_steps, len(features)))\n",
    "\n",
    "# # 填充三维数组\n",
    "# for source, group in grouped:\n",
    "#     data = group[features].values\n",
    "#     current_steps = data.shape[0]\n",
    "\n",
    "#     if current_steps < average_time_steps:\n",
    "#         fill_values = {\n",
    "#             'Breath': group['Breath'].mean(),\n",
    "#             'Heartrate': group['Heartrate'].mean(),\n",
    "#             'Sleepstate': group['Sleepstate'].median(),\n",
    "#             'Movement': 0\n",
    "#         }\n",
    "#         fill_array = np.array([[fill_values[feature] for feature in features]] * (average_time_steps - current_steps))\n",
    "#         full_data = np.vstack((data, fill_array))\n",
    "#     else:\n",
    "#         full_data = data[:average_time_steps, :]\n",
    "\n",
    "#     three_dim_array[source-1, :, :] = full_data\n",
    "\n",
    "# three_dim_array.shape  # 显示三维数组的形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签构造\n",
    "- 意识状态\n",
    "- GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = meta_data[\"意识状态\"].values\n",
    "# nb_classes = len(np.unique(labels, axis=0))\n",
    "# labels,nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_final_process(x,y):\n",
    "    nb_classes = len(np.unique(y, axis=0))\n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    enc.fit(y.reshape(-1, 1))\n",
    "    y = enc.transform(y.reshape(-1, 1)).toarray()\n",
    "\n",
    "    # # save orignal y because later we will use binary\n",
    "    # y_true = np.argmax(y_test, axis=1)\n",
    "    logging.info(f'x.shape: {x.shape}, y.shape: {y.shape}\\n')\n",
    "    if len(x.shape) == 2:  # if univariate\n",
    "        # add a dimension to make it multivariate with one dimension \n",
    "        x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "    input_shape = x.shape[1:]\n",
    "    logging.info(f'input_shape: {input_shape}\\n')\n",
    "    \n",
    "    return x,y,input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_name=\"fcn\"\n",
    "# root_dir=\"/data4/gsprivate/dl-4-tsc\"\n",
    "# output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + '' + '/' + \\\n",
    "#                     dataset_name + '/'\n",
    "                    \n",
    "# if create_directory(output_directory) is None:\n",
    "#     logging.info(\"Creating directory:{} None\".format(output_directory))\n",
    "\n",
    "# x,y,input_shape=data_final_process(final_data,labels)\n",
    "# fcn_classifier = geng.create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
    "# logging.info(f\"Classifier x.shape={x.shape} ,y.shape={y.shape}, input_shape={input_shape}, nb_classes={nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_name=\"cnn\"\n",
    "# root_dir=\"/data4/gsprivate/dl-4-tsc\"\n",
    "# output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + '' + '/' + \\\n",
    "#                     dataset_name + '/'\n",
    "                    \n",
    "# if create_directory(output_directory) is None:\n",
    "#     logging.info(\"Creating directory:{} None\".format(output_directory))\n",
    "\n",
    "# x,y,input_shape=data_final_process(final_data,labels)\n",
    "# cnn_classifier = geng.create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
    "# logging.info(f\"Classifier x.shape={x.shape} ,y.shape={y.shape}, input_shape={input_shape}, nb_classes={nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 08:13:03 INFO [root] [<module>:27] - 0.01\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'Kailuan'\n",
    "        self.batch = 16\n",
    "        self.lr = 0.01\n",
    "        self.nlayers = 2\n",
    "        self.emb_size = 64\n",
    "        self.nhead = 8\n",
    "        self.task_rate = 0.5\n",
    "        self.masking_ratio = 0.15\n",
    "        self.lamb = 0.8\n",
    "        self.epochs = 300\n",
    "        self.ratio_highest_attention = 0.5\n",
    "        self.avg = 'macro'\n",
    "        self.dropout = 0.01\n",
    "        self.nhid = 128\n",
    "        self.nhid_task = 128\n",
    "        self.nhid_tar = 128\n",
    "        self.task_type = 'classification'  # Or 'regression', depending on your task\n",
    "\n",
    "# 使用这个 Args 类来创建一个 args 对象\n",
    "args = Args()\n",
    "\n",
    "# 现在你可以像在命令行环境中一样使用这些参数了\n",
    "# 例如，打印学习率\n",
    "logging.info(args.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 08:13:03 INFO [root] [<module>:2] - prop: \n"
     ]
    }
   ],
   "source": [
    "prop = utils.get_prop(args)\n",
    "logging.info(\"prop: \" , prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 08:15:53 INFO [root] [<module>:7] - Creating directory:/data4/gsprivate/TARNet//results/TARnet/ None\n",
      "2024-01-28 08:15:53 INFO [root] [<module>:14] - \n",
      "---fold:1---\n",
      "2024-01-28 08:15:53 INFO [root] [<module>:15] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)\n",
      "2024-01-28 08:15:53 INFO [root] [<module>:17] - X_train_task.shape:torch.Size([128, 1088, 2]), y_train_task.shape:torch.Size([123]), X_test.shape:torch.Size([48, 1088, 2]), y_test.shape:torch.Size([41])\n",
      "2024-01-28 08:15:53 INFO [root] [<module>:21] - prop:{'batch': 16, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 300, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'nclasses': 3, 'seq_len': 1088, 'input_size': 2, 'device': device(type='cuda', index=0)}\n",
      "2024-01-28 08:15:53 INFO [root] [<module>:24] - Initializing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data4/gsprivate/TARNet//results/TARnet/ exist\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 7.00 KiB already allocated; 4.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitializing model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel intialized...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining start...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data4/gsPrivate/TARNet/utils.py:124\u001b[0m, in \u001b[0;36minitialize_training\u001b[0;34m(prop)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_training\u001b[39m(prop):\n\u001b[0;32m--> 124\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmultitask_transformer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultitaskTransformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtask_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnclasses\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq_len\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memb_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhid_tar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhid_task\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnlayers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m multitask_transformer_class\u001b[38;5;241m.\u001b[39mMultitaskTransformerModel(prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_type\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnclasses\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[1;32m    127\u001b[0m         prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memb_size\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnhead\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnhid\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnhid_tar\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnhid_task\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnlayers\u001b[39m\u001b[38;5;124m'\u001b[39m], prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(prop[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    129\u001b[0m     criterion_tar \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers[key] \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 7.00 KiB already allocated; 4.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "classifier_name=\"TARnet\"\n",
    "root_dir=\"/data4/gsprivate/TARNet/\"\n",
    "output_directory = root_dir + '/results/' + classifier_name + '/'\n",
    "        \n",
    "                    \n",
    "if geng.create_directory(output_directory) is None:\n",
    "    logging.info(\"Creating directory:{} None\".format(output_directory))\n",
    "\n",
    "# x,y,input_shape=data_final_process(final_data,labels)\n",
    "# mcnn_classifier = geng.create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
    "k_splits = geng.splits(final_data,labels,4)\n",
    "idx = 1\n",
    "for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:\n",
    "    logging.info(f\"\\n---fold:{idx}---\")\n",
    "    logging.info(f\"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}\")\n",
    "    \n",
    "    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)\n",
    "    logging.info(f\"X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}\")\n",
    "    \n",
    "    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None\n",
    "    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]\n",
    "    prop['device'] = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"prop:{prop}\")\n",
    "\n",
    "    idx+=1\n",
    "    logging.info('Initializing model...')\n",
    "    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)\n",
    "    logging.info('Model intialized...')\n",
    "\n",
    "    logging.info('Training start...')\n",
    "    utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)\n",
    "    logging.info('Training complete...')\n",
    "\n",
    "# logging.info(f\"Classifier x.shape={x.shape} ,y.shape={y.shape}, input_shape={input_shape}, nb_classes={nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture cap --no-stderr\n",
    "# logging.info(\"这将写入到文件中\")\n",
    "\n",
    "# geng.fit_splits_for_mcnn(mcnn_classifier,x,y,epochs=250)\n",
    "logging.info(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geng.fit_splits(cnn_classifier,x,y,batch_size=8,epochs=200)\n",
    "# logging.info('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "import tensorflow as tf\n",
    "\n",
    "# logging.info(torch.version.cuda)·\n",
    "# logging.info(torch.backends.cudnn.version())\n",
    "logging.info(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Retrieving all environment variables\n",
    "# env_vars = os.environ\n",
    "\n",
    "# # Displaying the environment variables\n",
    "# env_vars_dict = {key: env_vars[key] for key in env_vars}\n",
    "# env_vars_dict['LD_LIBRARY_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsprivate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
