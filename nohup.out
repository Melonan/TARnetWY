[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
Traceback (most recent call last):
  File "/home/beihang/anaconda3/bin/jupyter-nbconvert", line 11, in <module>
    sys.exit(main())
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/nbconvertapp.py", line 369, in start
    self.convert_notebooks()
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/nbconvertapp.py", line 541, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/nbconvertapp.py", line 506, in convert_single_notebook
    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/nbconvertapp.py", line 435, in export_single_notebook
    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/exporters/exporter.py", line 190, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/exporters/exporter.py", line 208, in from_file
    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/exporters/exporter.py", line 147, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/exporters/exporter.py", line 334, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/preprocessors/base.py", line 47, in __call__
    return self.preprocess(nb, resources)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/preprocessors/execute.py", line 84, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbconvert/preprocessors/execute.py", line 105, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/home/beihang/anaconda3/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/beihang/anaconda3/lib/python3.9/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import os
# from aeon.datasets.tsc_data_lists import multivariate_equal_length
import pandas as pd
import numpy as np
from sklearn import preprocessing
import sklearn
from tensorflow import keras
import tensorflow as tf
import numpy as np
import time 
# from utils import geng
import logconfig
import geng
import torch
import logging
# # 修改一个已存在的环境变量
# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']
# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']
# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']
# 使用设置好的环境变量
os.environ['CUDA_VISIBLE_DEVICES'] = "1"
logconfig.setup_logging(dir="./")
logging.info(f"PATH:{os.environ['PATH']}\nCUDA_HOME:{os.environ['CUDA_HOME']}")
# dataset_name = "170Kailuan-relu-5"
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mImportError[0m                               Traceback (most recent call last)
Cell [0;32mIn[1], line 7[0m
[1;32m      5[0m [38;5;28;01mfrom[39;00m [38;5;21;01msklearn[39;00m [38;5;28;01mimport[39;00m preprocessing
[1;32m      6[0m [38;5;28;01mimport[39;00m [38;5;21;01msklearn[39;00m
[0;32m----> 7[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m [38;5;28;01mimport[39;00m keras
[1;32m      8[0m [38;5;28;01mimport[39;00m [38;5;21;01mtensorflow[39;00m [38;5;28;01mas[39;00m [38;5;21;01mtf[39;00m
[1;32m      9[0m [38;5;28;01mimport[39;00m [38;5;21;01mnumpy[39;00m [38;5;28;01mas[39;00m [38;5;21;01mnp[39;00m

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py:45[0m
[1;32m     42[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m [38;5;28;01mimport[39;00m tf2 [38;5;28;01mas[39;00m _tf2
[1;32m     43[0m _tf2[38;5;241m.[39menable()
[0;32m---> 45[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01m_api[39;00m[38;5;21;01m.[39;00m[38;5;21;01mv2[39;00m [38;5;28;01mimport[39;00m __internal__
[1;32m     46[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01m_api[39;00m[38;5;21;01m.[39;00m[38;5;21;01mv2[39;00m [38;5;28;01mimport[39;00m __operators__
[1;32m     47[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01m_api[39;00m[38;5;21;01m.[39;00m[38;5;21;01mv2[39;00m [38;5;28;01mimport[39;00m audio

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8[0m
[1;32m      3[0m [38;5;124;03m"""Public API for tf._api.v2.__internal__ namespace[39;00m
[1;32m      4[0m [38;5;124;03m"""[39;00m
[1;32m      6[0m [38;5;28;01mimport[39;00m [38;5;21;01msys[39;00m [38;5;28;01mas[39;00m [38;5;21;01m_sys[39;00m
[0;32m----> 8[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01m_api[39;00m[38;5;21;01m.[39;00m[38;5;21;01mv2[39;00m[38;5;21;01m.[39;00m[38;5;21;01m__internal__[39;00m [38;5;28;01mimport[39;00m autograph
[1;32m      9[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01m_api[39;00m[38;5;21;01m.[39;00m[38;5;21;01mv2[39;00m[38;5;21;01m.[39;00m[38;5;21;01m__internal__[39;00m [38;5;28;01mimport[39;00m decorator
[1;32m     10[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01m_api[39;00m[38;5;21;01m.[39;00m[38;5;21;01mv2[39;00m[38;5;21;01m.[39;00m[38;5;21;01m__internal__[39;00m [38;5;28;01mimport[39;00m dispatch

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8[0m
[1;32m      3[0m [38;5;124;03m"""Public API for tf._api.v2.__internal__.autograph namespace[39;00m
[1;32m      4[0m [38;5;124;03m"""[39;00m
[1;32m      6[0m [38;5;28;01mimport[39;00m [38;5;21;01msys[39;00m [38;5;28;01mas[39;00m [38;5;21;01m_sys[39;00m
[0;32m----> 8[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mautograph[39;00m[38;5;21;01m.[39;00m[38;5;21;01mcore[39;00m[38;5;21;01m.[39;00m[38;5;21;01mag_ctx[39;00m [38;5;28;01mimport[39;00m control_status_ctx [38;5;66;03m# line: 34[39;00m
[1;32m      9[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mautograph[39;00m[38;5;21;01m.[39;00m[38;5;21;01mimpl[39;00m[38;5;21;01m.[39;00m[38;5;21;01mapi[39;00m [38;5;28;01mimport[39;00m tf_convert

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21[0m
[1;32m     18[0m [38;5;28;01mimport[39;00m [38;5;21;01minspect[39;00m
[1;32m     19[0m [38;5;28;01mimport[39;00m [38;5;21;01mthreading[39;00m
[0;32m---> 21[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mautograph[39;00m[38;5;21;01m.[39;00m[38;5;21;01mutils[39;00m [38;5;28;01mimport[39;00m ag_logging
[1;32m     22[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mutil[39;00m[38;5;21;01m.[39;00m[38;5;21;01mtf_export[39;00m [38;5;28;01mimport[39;00m tf_export
[1;32m     25[0m stacks [38;5;241m=[39m threading[38;5;241m.[39mlocal()

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17[0m
[1;32m      1[0m [38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.[39;00m
[1;32m      2[0m [38;5;66;03m#[39;00m
[1;32m      3[0m [38;5;66;03m# Licensed under the Apache License, Version 2.0 (the "License");[39;00m
[0;32m   (...)[0m
[1;32m     13[0m [38;5;66;03m# limitations under the License.[39;00m
[1;32m     14[0m [38;5;66;03m# ==============================================================================[39;00m
[1;32m     15[0m [38;5;124;03m"""Utility module that contains APIs usable in the generated code."""[39;00m
[0;32m---> 17[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mautograph[39;00m[38;5;21;01m.[39;00m[38;5;21;01mutils[39;00m[38;5;21;01m.[39;00m[38;5;21;01mcontext_managers[39;00m [38;5;28;01mimport[39;00m control_dependency_on_returns
[1;32m     18[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mautograph[39;00m[38;5;21;01m.[39;00m[38;5;21;01mutils[39;00m[38;5;21;01m.[39;00m[38;5;21;01mmisc[39;00m [38;5;28;01mimport[39;00m alias_tensors
[1;32m     19[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mautograph[39;00m[38;5;21;01m.[39;00m[38;5;21;01mutils[39;00m[38;5;21;01m.[39;00m[38;5;21;01mtensor_list[39;00m [38;5;28;01mimport[39;00m dynamic_list_append

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19[0m
[1;32m     15[0m [38;5;124;03m"""Various context managers."""[39;00m
[1;32m     17[0m [38;5;28;01mimport[39;00m [38;5;21;01mcontextlib[39;00m
[0;32m---> 19[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mframework[39;00m [38;5;28;01mimport[39;00m ops
[1;32m     20[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpython[39;00m[38;5;21;01m.[39;00m[38;5;21;01mops[39;00m [38;5;28;01mimport[39;00m tensor_array_ops
[1;32m     23[0m [38;5;28;01mdef[39;00m [38;5;21mcontrol_dependency_on_returns[39m(return_value):

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:33[0m
[1;32m     30[0m [38;5;28;01mfrom[39;00m [38;5;21;01mnumpy[39;00m [38;5;28;01mimport[39;00m typing [38;5;28;01mas[39;00m npt
[1;32m     32[0m [38;5;28;01mfrom[39;00m [38;5;21;01mgoogle[39;00m[38;5;21;01m.[39;00m[38;5;21;01mprotobuf[39;00m [38;5;28;01mimport[39;00m message
[0;32m---> 33[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mcore[39;00m[38;5;21;01m.[39;00m[38;5;21;01mframework[39;00m [38;5;28;01mimport[39;00m attr_value_pb2
[1;32m     34[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mcore[39;00m[38;5;21;01m.[39;00m[38;5;21;01mframework[39;00m [38;5;28;01mimport[39;00m full_type_pb2
[1;32m     35[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtensorflow[39;00m[38;5;21;01m.[39;00m[38;5;21;01mcore[39;00m[38;5;21;01m.[39;00m[38;5;21;01mframework[39;00m [38;5;28;01mimport[39;00m function_pb2

File [0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/core/framework/attr_value_pb2.py:5[0m
[1;32m      1[0m [38;5;66;03m# -*- coding: utf-8 -*-[39;00m
[1;32m      2[0m [38;5;66;03m# Generated by the protocol buffer compiler.  DO NOT EDIT![39;00m
[1;32m      3[0m [38;5;66;03m# source: tensorflow/core/framework/attr_value.proto[39;00m
[1;32m      4[0m [38;5;124;03m"""Generated protocol buffer code."""[39;00m
[0;32m----> 5[0m [38;5;28;01mfrom[39;00m [38;5;21;01mgoogle[39;00m[38;5;21;01m.[39;00m[38;5;21;01mprotobuf[39;00m[38;5;21;01m.[39;00m[38;5;21;01minternal[39;00m [38;5;28;01mimport[39;00m builder [38;5;28;01mas[39;00m _builder
[1;32m      6[0m [38;5;28;01mfrom[39;00m [38;5;21;01mgoogle[39;00m[38;5;21;01m.[39;00m[38;5;21;01mprotobuf[39;00m [38;5;28;01mimport[39;00m descriptor [38;5;28;01mas[39;00m _descriptor
[1;32m      7[0m [38;5;28;01mfrom[39;00m [38;5;21;01mgoogle[39;00m[38;5;21;01m.[39;00m[38;5;21;01mprotobuf[39;00m [38;5;28;01mimport[39;00m descriptor_pool [38;5;28;01mas[39;00m _descriptor_pool

[0;31mImportError[0m: cannot import name 'builder' from 'google.protobuf.internal' (/home/beihang/anaconda3/lib/python3.9/site-packages/google/protobuf/internal/__init__.py)
ImportError: cannot import name 'builder' from 'google.protobuf.internal' (/home/beihang/anaconda3/lib/python3.9/site-packages/google/protobuf/internal/__init__.py)

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 12:31:14.721225: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 12:31:18.098184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Writing 111663985 bytes to multi-geng.nbconvert.ipynb
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 16:14:36.398606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 16:14:40.563898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    # x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    # x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    # logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda:0' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-17 16:14:51 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-17 16:14:51 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-17 16:14:51 INFO [root] [preprocess:100] - --Preprocessing--
----- stderr -----
2024-05-17 16:14:51 INFO [root] [preprocess:101] - [preprocess] preprocessing X_train.shape:(123, 1088, 2), y_train.shape:(123,), X_test.shape:(41, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:14:51 INFO [root] [preprocess:111] - [preprocess] after process X_train.shape:(128, 1088, 2), y_train.shape:(123,), X_test.shape:(64, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:14:51 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([128, 1088, 2]), y_train_task.shape:torch.Size([123]), X_test.shape:torch.Size([64, 1088, 2]), y_test.shape:torch.Size([41])
----- stderr -----
2024-05-17 16:14:51 INFO [root] [<module>:16] - prop:{'batch': 64, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 300, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'nclasses': 3, 'seq_len': 1088, 'input_size': 2, 'device': device(type='cuda', index=0)}
----- stderr -----
2024-05-17 16:14:51 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:14:58 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-17 16:14:58 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-17 16:14:58 INFO [root] [attention_sampled_masking_heuristic:142] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-17 16:14:58 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([128, 1088]),index.shape:torch.Size([128, 544])
----- stderr -----
2024-05-17 16:14:58 INFO [root] [random_instance_masking:157] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,indices.shape:(128, 164)
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:14:58 INFO [root] [random_instance_masking:163] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,boolean_indices.shape:(128, 1088),boolean_indices_masked.shape:(128, 1088, 2),boolean_indices_unmasked.shape:(128, 1088, 2)
----- stderr -----
2024-05-17 16:14:58 INFO [root] [random_instance_masking:173] - [random_instance_masking] :X_train_tar.shape:torch.Size([128, 1088, 2]), y_train_tar_masked.shape:torch.Size([128, 328]), y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:14:58 INFO [root] [multitask_train:209] - [multitask_train] X_train_task :torch.Size([128, 1088, 2]),X_train_tar.shape:torch.Size([128, 1088, 2]),y_train_task.shape:torch.Size([123]),y_train_tar_masked.shape:torch.Size([128, 328]),y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:14:58 INFO [root] [multitask_train:221] - [multitask_train] batch:0, num_inst:64, start:0, end:64
----- stderr -----
2024-05-17 16:14:58 INFO [root] [multitask_train:228] - [multitask_train] batch:0,batched_input_tar.shape:torch.Size([64, 1088, 2]),batched_input_task.shape:torch.Size([64, 1088, 2]), batched_boolean_indices_masked.shape:(64, 1088, 2),batched_boolean_indices_unmasked.shape:(64, 1088, 2)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:314[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    308[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    309[0m     
[1;32m    310[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    311[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    312[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 314[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    315[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    316[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    318[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    319[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:229[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    227[0m batched_boolean_indices_unmasked [38;5;241m=[39m boolean_indices_unmasked[start : end]
[1;32m    228[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m,batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 229[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m [43mcompute_tar_loss[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43m\[49m
[1;32m    230[0m [43m    [49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_masked[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_unmasked[49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    232[0m attn, loss_task [38;5;241m=[39m compute_task_loss(prop[[38;5;124m'[39m[38;5;124mnclasses[39m[38;5;124m'[39m], model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_task, y_train_task, \
[1;32m    233[0m     batched_input_task, prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m], num_inst, start)
[1;32m    235[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 

File [0;32m/data4/gsprivate/TARnetWY/utils.py:181[0m, in [0;36mcompute_tar_loss[0;34m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)[0m
[1;32m    178[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_tar_loss[39m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, \
[1;32m    179[0m                     batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start):
[1;32m    180[0m     model[38;5;241m.[39mtrain()
[0;32m--> 181[0m     out_tar [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mreconstruction[39;49m[38;5;124;43m'[39;49m[43m)[49m[[38;5;241m0[39m]
[1;32m    182[0m     logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_tar_loss] out_tar.shape:[39m[38;5;132;01m{[39;00mout_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    183[0m     out_tar_masked [38;5;241m=[39m torch[38;5;241m.[39mas_tensor(out_tar[torch[38;5;241m.[39mas_tensor(batched_boolean_indices_masked)][38;5;241m.[39mreshape(out_tar[38;5;241m.[39mshape[[38;5;241m0[39m], [38;5;241m-[39m[38;5;241m1[39m), device [38;5;241m=[39m device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/multitask_transformer_class.py:118[0m, in [0;36mMultitaskTransformerModel.forward[0;34m(self, x, task_type)[0m
[1;32m    116[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, x, task_type):
[1;32m    117[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtrunk_net(x[38;5;241m.[39mpermute([38;5;241m1[39m, [38;5;241m0[39m, [38;5;241m2[39m))
[0;32m--> 118[0m     x, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtransformer_encoder[49m[43m([49m[43mx[49m[43m)[49m
[1;32m    119[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mbatch_norm(x)
[1;32m    120[0m     [38;5;66;03m# x : seq_len x batch x emb_size[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:125[0m, in [0;36mTransformerEncoder.forward[0;34m(self, src, mask, src_key_padding_mask)[0m
[1;32m    122[0m attn_output [38;5;241m=[39m torch[38;5;241m.[39mzeros((src[38;5;241m.[39mshape[[38;5;241m1[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m]), device [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mdevice) [38;5;66;03m# batch, seq_len, seq_len[39;00m
[1;32m    124[0m [38;5;28;01mfor[39;00m mod [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mlayers:
[0;32m--> 125[0m     output, attn [38;5;241m=[39m [43mmod[49m[43m([49m[43moutput[49m[43m,[49m[43m [49m[43msrc_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mmask[49m[43m,[49m[43m [49m[43msrc_key_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m    126[0m     attn_output [38;5;241m+[39m[38;5;241m=[39m attn
[1;32m    128[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mnorm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:79[0m, in [0;36mTransformerEncoderLayer.forward[0;34m(self, src, src_mask, src_key_padding_mask)[0m
[1;32m     70[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, src, src_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m, src_key_padding_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m):
[1;32m     71[0m [38;5;250m    [39m[38;5;124mr[39m[38;5;124;03m"""Pass the input through the encoder layer.[39;00m
[1;32m     72[0m [38;5;124;03m    Args:[39;00m
[1;32m     73[0m [38;5;124;03m        src: the sequence to the encoder layer (required).[39;00m
[0;32m   (...)[0m
[1;32m     77[0m [38;5;124;03m        see the docs in Transformer class.[39;00m
[1;32m     78[0m [38;5;124;03m    """[39;00m
[0;32m---> 79[0m     src2, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mself_attn[49m[43m([49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43mattn_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_mask[49m[43m,[49m
[1;32m     80[0m [43m                          [49m[43mkey_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m     81[0m     src [38;5;241m=[39m src [38;5;241m+[39m [38;5;28mself[39m[38;5;241m.[39mdropout1(src2)
[1;32m     82[0m     src [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mnorm1(src)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167[0m, in [0;36mMultiheadAttention.forward[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)[0m
[1;32m   1156[0m     attn_output, attn_output_weights [38;5;241m=[39m F[38;5;241m.[39mmulti_head_attention_forward(
[1;32m   1157[0m         query, key, value, [38;5;28mself[39m[38;5;241m.[39membed_dim, [38;5;28mself[39m[38;5;241m.[39mnum_heads,
[1;32m   1158[0m         [38;5;28mself[39m[38;5;241m.[39min_proj_weight, [38;5;28mself[39m[38;5;241m.[39min_proj_bias,
[0;32m   (...)[0m
[1;32m   1164[0m         q_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mq_proj_weight, k_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mk_proj_weight,
[1;32m   1165[0m         v_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mv_proj_weight, average_attn_weights[38;5;241m=[39maverage_attn_weights)
[1;32m   1166[0m [38;5;28;01melse[39;00m:
[0;32m-> 1167[0m     attn_output, attn_output_weights [38;5;241m=[39m [43mF[49m[38;5;241;43m.[39;49m[43mmulti_head_attention_forward[49m[43m([49m
[1;32m   1168[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mkey[49m[43m,[49m[43m [49m[43mvalue[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43membed_dim[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_heads[49m[43m,[49m
[1;32m   1169[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_weight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_bias[49m[43m,[49m
[1;32m   1170[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_k[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_v[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43madd_zero_attn[49m[43m,[49m
[1;32m   1171[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdropout[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mbias[49m[43m,[49m
[1;32m   1172[0m [43m        [49m[43mtraining[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtraining[49m[43m,[49m
[1;32m   1173[0m [43m        [49m[43mkey_padding_mask[49m[38;5;241;43m=[39;49m[43mkey_padding_mask[49m[43m,[49m[43m [49m[43mneed_weights[49m[38;5;241;43m=[39;49m[43mneed_weights[49m[43m,[49m
[1;32m   1174[0m [43m        [49m[43mattn_mask[49m[38;5;241;43m=[39;49m[43mattn_mask[49m[43m,[49m[43m [49m[43maverage_attn_weights[49m[38;5;241;43m=[39;49m[43maverage_attn_weights[49m[43m)[49m
[1;32m   1175[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_first [38;5;129;01mand[39;00m is_batched:
[1;32m   1176[0m     [38;5;28;01mreturn[39;00m attn_output[38;5;241m.[39mtranspose([38;5;241m1[39m, [38;5;241m0[39m), attn_output_weights

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:5161[0m, in [0;36mmulti_head_attention_forward[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)[0m
[1;32m   5159[0m [38;5;28;01melse[39;00m:
[1;32m   5160[0m     attn_output_weights [38;5;241m=[39m torch[38;5;241m.[39mbmm(q_scaled, k[38;5;241m.[39mtranspose([38;5;241m-[39m[38;5;241m2[39m, [38;5;241m-[39m[38;5;241m1[39m))
[0;32m-> 5161[0m attn_output_weights [38;5;241m=[39m [43msoftmax[49m[43m([49m[43mattn_output_weights[49m[43m,[49m[43m [49m[43mdim[49m[38;5;241;43m=[39;49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[1;32m   5162[0m [38;5;28;01mif[39;00m dropout_p [38;5;241m>[39m [38;5;241m0.0[39m:
[1;32m   5163[0m     attn_output_weights [38;5;241m=[39m dropout(attn_output_weights, p[38;5;241m=[39mdropout_p)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:1841[0m, in [0;36msoftmax[0;34m(input, dim, _stacklevel, dtype)[0m
[1;32m   1839[0m     dim [38;5;241m=[39m _get_softmax_dim([38;5;124m"[39m[38;5;124msoftmax[39m[38;5;124m"[39m, [38;5;28minput[39m[38;5;241m.[39mdim(), _stacklevel)
[1;32m   1840[0m [38;5;28;01mif[39;00m dtype [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m-> 1841[0m     ret [38;5;241m=[39m [38;5;28;43minput[39;49m[38;5;241;43m.[39;49m[43msoftmax[49m[43m([49m[43mdim[49m[43m)[49m
[1;32m   1842[0m [38;5;28;01melse[39;00m:
[1;32m   1843[0m     ret [38;5;241m=[39m [38;5;28minput[39m[38;5;241m.[39msoftmax(dim, dtype[38;5;241m=[39mdtype)

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 11.91 GiB total capacity; 8.25 GiB already allocated; 1.74 GiB free; 9.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 16:19:14.034644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 16:19:16.830227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    # x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    # x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    # logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda:0' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-17 16:19:22 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-17 16:19:22 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-17 16:19:22 INFO [root] [preprocess:100] - --Preprocessing--
----- stderr -----
2024-05-17 16:19:22 INFO [root] [preprocess:101] - [preprocess] preprocessing X_train.shape:(123, 1088, 2), y_train.shape:(123,), X_test.shape:(41, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:19:22 INFO [root] [preprocess:111] - [preprocess] after process X_train.shape:(128, 1088, 2), y_train.shape:(123,), X_test.shape:(64, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:19:22 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([128, 1088, 2]), y_train_task.shape:torch.Size([123]), X_test.shape:torch.Size([64, 1088, 2]), y_test.shape:torch.Size([41])
----- stderr -----
2024-05-17 16:19:22 INFO [root] [<module>:16] - prop:{'batch': 64, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 300, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'nclasses': 3, 'seq_len': 1088, 'input_size': 2, 'device': device(type='cuda', index=0)}
----- stderr -----
2024-05-17 16:19:22 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:19:25 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-17 16:19:25 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-17 16:19:25 INFO [root] [attention_sampled_masking_heuristic:142] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-17 16:19:25 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([128, 1088]),index.shape:torch.Size([128, 544])
----- stderr -----
2024-05-17 16:19:25 INFO [root] [random_instance_masking:157] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,indices.shape:(128, 164)
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:19:26 INFO [root] [random_instance_masking:163] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,boolean_indices.shape:(128, 1088),boolean_indices_masked.shape:(128, 1088, 2),boolean_indices_unmasked.shape:(128, 1088, 2)
----- stderr -----
2024-05-17 16:19:26 INFO [root] [random_instance_masking:173] - [random_instance_masking] :X_train_tar.shape:torch.Size([128, 1088, 2]), y_train_tar_masked.shape:torch.Size([128, 328]), y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:19:26 INFO [root] [multitask_train:209] - [multitask_train] X_train_task :torch.Size([128, 1088, 2]),X_train_tar.shape:torch.Size([128, 1088, 2]),y_train_task.shape:torch.Size([123]),y_train_tar_masked.shape:torch.Size([128, 328]),y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:19:26 INFO [root] [multitask_train:221] - [multitask_train] batch:0, num_inst:64, start:0, end:64
----- stderr -----
2024-05-17 16:19:26 INFO [root] [multitask_train:228] - [multitask_train] batch:0,batched_input_tar.shape:torch.Size([64, 1088, 2]),batched_input_task.shape:torch.Size([64, 1088, 2]), batched_boolean_indices_masked.shape:(64, 1088, 2),batched_boolean_indices_unmasked.shape:(64, 1088, 2)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:314[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    308[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    309[0m     
[1;32m    310[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    311[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    312[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 314[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    315[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    316[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    318[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    319[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:229[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    227[0m batched_boolean_indices_unmasked [38;5;241m=[39m boolean_indices_unmasked[start : end]
[1;32m    228[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m,batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 229[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m [43mcompute_tar_loss[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43m\[49m
[1;32m    230[0m [43m    [49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_masked[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_unmasked[49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    232[0m attn, loss_task [38;5;241m=[39m compute_task_loss(prop[[38;5;124m'[39m[38;5;124mnclasses[39m[38;5;124m'[39m], model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_task, y_train_task, \
[1;32m    233[0m     batched_input_task, prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m], num_inst, start)
[1;32m    235[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 

File [0;32m/data4/gsprivate/TARnetWY/utils.py:181[0m, in [0;36mcompute_tar_loss[0;34m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)[0m
[1;32m    178[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_tar_loss[39m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, \
[1;32m    179[0m                     batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start):
[1;32m    180[0m     model[38;5;241m.[39mtrain()
[0;32m--> 181[0m     out_tar [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mreconstruction[39;49m[38;5;124;43m'[39;49m[43m)[49m[[38;5;241m0[39m]
[1;32m    182[0m     logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_tar_loss] out_tar.shape:[39m[38;5;132;01m{[39;00mout_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    183[0m     out_tar_masked [38;5;241m=[39m torch[38;5;241m.[39mas_tensor(out_tar[torch[38;5;241m.[39mas_tensor(batched_boolean_indices_masked)][38;5;241m.[39mreshape(out_tar[38;5;241m.[39mshape[[38;5;241m0[39m], [38;5;241m-[39m[38;5;241m1[39m), device [38;5;241m=[39m device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/multitask_transformer_class.py:118[0m, in [0;36mMultitaskTransformerModel.forward[0;34m(self, x, task_type)[0m
[1;32m    116[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, x, task_type):
[1;32m    117[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtrunk_net(x[38;5;241m.[39mpermute([38;5;241m1[39m, [38;5;241m0[39m, [38;5;241m2[39m))
[0;32m--> 118[0m     x, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtransformer_encoder[49m[43m([49m[43mx[49m[43m)[49m
[1;32m    119[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mbatch_norm(x)
[1;32m    120[0m     [38;5;66;03m# x : seq_len x batch x emb_size[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:125[0m, in [0;36mTransformerEncoder.forward[0;34m(self, src, mask, src_key_padding_mask)[0m
[1;32m    122[0m attn_output [38;5;241m=[39m torch[38;5;241m.[39mzeros((src[38;5;241m.[39mshape[[38;5;241m1[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m]), device [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mdevice) [38;5;66;03m# batch, seq_len, seq_len[39;00m
[1;32m    124[0m [38;5;28;01mfor[39;00m mod [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mlayers:
[0;32m--> 125[0m     output, attn [38;5;241m=[39m [43mmod[49m[43m([49m[43moutput[49m[43m,[49m[43m [49m[43msrc_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mmask[49m[43m,[49m[43m [49m[43msrc_key_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m    126[0m     attn_output [38;5;241m+[39m[38;5;241m=[39m attn
[1;32m    128[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mnorm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:79[0m, in [0;36mTransformerEncoderLayer.forward[0;34m(self, src, src_mask, src_key_padding_mask)[0m
[1;32m     70[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, src, src_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m, src_key_padding_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m):
[1;32m     71[0m [38;5;250m    [39m[38;5;124mr[39m[38;5;124;03m"""Pass the input through the encoder layer.[39;00m
[1;32m     72[0m [38;5;124;03m    Args:[39;00m
[1;32m     73[0m [38;5;124;03m        src: the sequence to the encoder layer (required).[39;00m
[0;32m   (...)[0m
[1;32m     77[0m [38;5;124;03m        see the docs in Transformer class.[39;00m
[1;32m     78[0m [38;5;124;03m    """[39;00m
[0;32m---> 79[0m     src2, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mself_attn[49m[43m([49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43mattn_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_mask[49m[43m,[49m
[1;32m     80[0m [43m                          [49m[43mkey_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m     81[0m     src [38;5;241m=[39m src [38;5;241m+[39m [38;5;28mself[39m[38;5;241m.[39mdropout1(src2)
[1;32m     82[0m     src [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mnorm1(src)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167[0m, in [0;36mMultiheadAttention.forward[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)[0m
[1;32m   1156[0m     attn_output, attn_output_weights [38;5;241m=[39m F[38;5;241m.[39mmulti_head_attention_forward(
[1;32m   1157[0m         query, key, value, [38;5;28mself[39m[38;5;241m.[39membed_dim, [38;5;28mself[39m[38;5;241m.[39mnum_heads,
[1;32m   1158[0m         [38;5;28mself[39m[38;5;241m.[39min_proj_weight, [38;5;28mself[39m[38;5;241m.[39min_proj_bias,
[0;32m   (...)[0m
[1;32m   1164[0m         q_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mq_proj_weight, k_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mk_proj_weight,
[1;32m   1165[0m         v_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mv_proj_weight, average_attn_weights[38;5;241m=[39maverage_attn_weights)
[1;32m   1166[0m [38;5;28;01melse[39;00m:
[0;32m-> 1167[0m     attn_output, attn_output_weights [38;5;241m=[39m [43mF[49m[38;5;241;43m.[39;49m[43mmulti_head_attention_forward[49m[43m([49m
[1;32m   1168[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mkey[49m[43m,[49m[43m [49m[43mvalue[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43membed_dim[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_heads[49m[43m,[49m
[1;32m   1169[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_weight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_bias[49m[43m,[49m
[1;32m   1170[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_k[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_v[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43madd_zero_attn[49m[43m,[49m
[1;32m   1171[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdropout[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mbias[49m[43m,[49m
[1;32m   1172[0m [43m        [49m[43mtraining[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtraining[49m[43m,[49m
[1;32m   1173[0m [43m        [49m[43mkey_padding_mask[49m[38;5;241;43m=[39;49m[43mkey_padding_mask[49m[43m,[49m[43m [49m[43mneed_weights[49m[38;5;241;43m=[39;49m[43mneed_weights[49m[43m,[49m
[1;32m   1174[0m [43m        [49m[43mattn_mask[49m[38;5;241;43m=[39;49m[43mattn_mask[49m[43m,[49m[43m [49m[43maverage_attn_weights[49m[38;5;241;43m=[39;49m[43maverage_attn_weights[49m[43m)[49m
[1;32m   1175[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_first [38;5;129;01mand[39;00m is_batched:
[1;32m   1176[0m     [38;5;28;01mreturn[39;00m attn_output[38;5;241m.[39mtranspose([38;5;241m1[39m, [38;5;241m0[39m), attn_output_weights

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:5161[0m, in [0;36mmulti_head_attention_forward[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)[0m
[1;32m   5159[0m [38;5;28;01melse[39;00m:
[1;32m   5160[0m     attn_output_weights [38;5;241m=[39m torch[38;5;241m.[39mbmm(q_scaled, k[38;5;241m.[39mtranspose([38;5;241m-[39m[38;5;241m2[39m, [38;5;241m-[39m[38;5;241m1[39m))
[0;32m-> 5161[0m attn_output_weights [38;5;241m=[39m [43msoftmax[49m[43m([49m[43mattn_output_weights[49m[43m,[49m[43m [49m[43mdim[49m[38;5;241;43m=[39;49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[1;32m   5162[0m [38;5;28;01mif[39;00m dropout_p [38;5;241m>[39m [38;5;241m0.0[39m:
[1;32m   5163[0m     attn_output_weights [38;5;241m=[39m dropout(attn_output_weights, p[38;5;241m=[39mdropout_p)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:1841[0m, in [0;36msoftmax[0;34m(input, dim, _stacklevel, dtype)[0m
[1;32m   1839[0m     dim [38;5;241m=[39m _get_softmax_dim([38;5;124m"[39m[38;5;124msoftmax[39m[38;5;124m"[39m, [38;5;28minput[39m[38;5;241m.[39mdim(), _stacklevel)
[1;32m   1840[0m [38;5;28;01mif[39;00m dtype [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m-> 1841[0m     ret [38;5;241m=[39m [38;5;28;43minput[39;49m[38;5;241;43m.[39;49m[43msoftmax[49m[43m([49m[43mdim[49m[43m)[49m
[1;32m   1842[0m [38;5;28;01melse[39;00m:
[1;32m   1843[0m     ret [38;5;241m=[39m [38;5;28minput[39m[38;5;241m.[39msoftmax(dim, dtype[38;5;241m=[39mdtype)

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 11.91 GiB total capacity; 8.25 GiB already allocated; 1.74 GiB free; 9.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 16:23:35.412910: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 16:23:37.696194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    # x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    # x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    # logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda:0' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-17 16:23:42 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-17 16:23:42 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-17 16:23:42 INFO [root] [preprocess:100] - --Preprocessing--
----- stderr -----
2024-05-17 16:23:42 INFO [root] [preprocess:101] - [preprocess] preprocessing X_train.shape:(123, 1088, 2), y_train.shape:(123,), X_test.shape:(41, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:23:42 INFO [root] [preprocess:111] - [preprocess] after process X_train.shape:(128, 1088, 2), y_train.shape:(123,), X_test.shape:(64, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:23:42 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([128, 1088, 2]), y_train_task.shape:torch.Size([123]), X_test.shape:torch.Size([64, 1088, 2]), y_test.shape:torch.Size([41])
----- stderr -----
2024-05-17 16:23:42 INFO [root] [<module>:16] - prop:{'batch': 64, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 300, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'nclasses': 3, 'seq_len': 1088, 'input_size': 2, 'device': device(type='cuda', index=0)}
----- stderr -----
2024-05-17 16:23:42 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:23:45 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-17 16:23:45 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-17 16:23:45 INFO [root] [attention_sampled_masking_heuristic:142] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-17 16:23:45 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([128, 1088]),index.shape:torch.Size([128, 544])
----- stderr -----
2024-05-17 16:23:45 INFO [root] [random_instance_masking:157] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,indices.shape:(128, 164)
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:23:45 INFO [root] [random_instance_masking:163] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,boolean_indices.shape:(128, 1088),boolean_indices_masked.shape:(128, 1088, 2),boolean_indices_unmasked.shape:(128, 1088, 2)
----- stderr -----
2024-05-17 16:23:45 INFO [root] [random_instance_masking:173] - [random_instance_masking] :X_train_tar.shape:torch.Size([128, 1088, 2]), y_train_tar_masked.shape:torch.Size([128, 328]), y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:23:45 INFO [root] [multitask_train:209] - [multitask_train] X_train_task :torch.Size([128, 1088, 2]),X_train_tar.shape:torch.Size([128, 1088, 2]),y_train_task.shape:torch.Size([123]),y_train_tar_masked.shape:torch.Size([128, 328]),y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:23:45 INFO [root] [multitask_train:221] - [multitask_train] batch:0, num_inst:64, start:0, end:64
----- stderr -----
2024-05-17 16:23:45 INFO [root] [multitask_train:228] - [multitask_train] batch:0,batched_input_tar.shape:torch.Size([64, 1088, 2]),batched_input_task.shape:torch.Size([64, 1088, 2]), batched_boolean_indices_masked.shape:(64, 1088, 2),batched_boolean_indices_unmasked.shape:(64, 1088, 2)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:314[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    308[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    309[0m     
[1;32m    310[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    311[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    312[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 314[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    315[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    316[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    318[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    319[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:229[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    227[0m batched_boolean_indices_unmasked [38;5;241m=[39m boolean_indices_unmasked[start : end]
[1;32m    228[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m,batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 229[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m [43mcompute_tar_loss[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43m\[49m
[1;32m    230[0m [43m    [49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_masked[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_unmasked[49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    232[0m attn, loss_task [38;5;241m=[39m compute_task_loss(prop[[38;5;124m'[39m[38;5;124mnclasses[39m[38;5;124m'[39m], model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_task, y_train_task, \
[1;32m    233[0m     batched_input_task, prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m], num_inst, start)
[1;32m    235[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 

File [0;32m/data4/gsprivate/TARnetWY/utils.py:181[0m, in [0;36mcompute_tar_loss[0;34m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)[0m
[1;32m    178[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_tar_loss[39m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, \
[1;32m    179[0m                     batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start):
[1;32m    180[0m     model[38;5;241m.[39mtrain()
[0;32m--> 181[0m     out_tar [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mreconstruction[39;49m[38;5;124;43m'[39;49m[43m)[49m[[38;5;241m0[39m]
[1;32m    182[0m     logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_tar_loss] out_tar.shape:[39m[38;5;132;01m{[39;00mout_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    183[0m     out_tar_masked [38;5;241m=[39m torch[38;5;241m.[39mas_tensor(out_tar[torch[38;5;241m.[39mas_tensor(batched_boolean_indices_masked)][38;5;241m.[39mreshape(out_tar[38;5;241m.[39mshape[[38;5;241m0[39m], [38;5;241m-[39m[38;5;241m1[39m), device [38;5;241m=[39m device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/multitask_transformer_class.py:118[0m, in [0;36mMultitaskTransformerModel.forward[0;34m(self, x, task_type)[0m
[1;32m    116[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, x, task_type):
[1;32m    117[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtrunk_net(x[38;5;241m.[39mpermute([38;5;241m1[39m, [38;5;241m0[39m, [38;5;241m2[39m))
[0;32m--> 118[0m     x, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtransformer_encoder[49m[43m([49m[43mx[49m[43m)[49m
[1;32m    119[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mbatch_norm(x)
[1;32m    120[0m     [38;5;66;03m# x : seq_len x batch x emb_size[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:125[0m, in [0;36mTransformerEncoder.forward[0;34m(self, src, mask, src_key_padding_mask)[0m
[1;32m    122[0m attn_output [38;5;241m=[39m torch[38;5;241m.[39mzeros((src[38;5;241m.[39mshape[[38;5;241m1[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m]), device [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mdevice) [38;5;66;03m# batch, seq_len, seq_len[39;00m
[1;32m    124[0m [38;5;28;01mfor[39;00m mod [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mlayers:
[0;32m--> 125[0m     output, attn [38;5;241m=[39m [43mmod[49m[43m([49m[43moutput[49m[43m,[49m[43m [49m[43msrc_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mmask[49m[43m,[49m[43m [49m[43msrc_key_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m    126[0m     attn_output [38;5;241m+[39m[38;5;241m=[39m attn
[1;32m    128[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mnorm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:79[0m, in [0;36mTransformerEncoderLayer.forward[0;34m(self, src, src_mask, src_key_padding_mask)[0m
[1;32m     70[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, src, src_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m, src_key_padding_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m):
[1;32m     71[0m [38;5;250m    [39m[38;5;124mr[39m[38;5;124;03m"""Pass the input through the encoder layer.[39;00m
[1;32m     72[0m [38;5;124;03m    Args:[39;00m
[1;32m     73[0m [38;5;124;03m        src: the sequence to the encoder layer (required).[39;00m
[0;32m   (...)[0m
[1;32m     77[0m [38;5;124;03m        see the docs in Transformer class.[39;00m
[1;32m     78[0m [38;5;124;03m    """[39;00m
[0;32m---> 79[0m     src2, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mself_attn[49m[43m([49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43mattn_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_mask[49m[43m,[49m
[1;32m     80[0m [43m                          [49m[43mkey_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m     81[0m     src [38;5;241m=[39m src [38;5;241m+[39m [38;5;28mself[39m[38;5;241m.[39mdropout1(src2)
[1;32m     82[0m     src [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mnorm1(src)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167[0m, in [0;36mMultiheadAttention.forward[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)[0m
[1;32m   1156[0m     attn_output, attn_output_weights [38;5;241m=[39m F[38;5;241m.[39mmulti_head_attention_forward(
[1;32m   1157[0m         query, key, value, [38;5;28mself[39m[38;5;241m.[39membed_dim, [38;5;28mself[39m[38;5;241m.[39mnum_heads,
[1;32m   1158[0m         [38;5;28mself[39m[38;5;241m.[39min_proj_weight, [38;5;28mself[39m[38;5;241m.[39min_proj_bias,
[0;32m   (...)[0m
[1;32m   1164[0m         q_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mq_proj_weight, k_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mk_proj_weight,
[1;32m   1165[0m         v_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mv_proj_weight, average_attn_weights[38;5;241m=[39maverage_attn_weights)
[1;32m   1166[0m [38;5;28;01melse[39;00m:
[0;32m-> 1167[0m     attn_output, attn_output_weights [38;5;241m=[39m [43mF[49m[38;5;241;43m.[39;49m[43mmulti_head_attention_forward[49m[43m([49m
[1;32m   1168[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mkey[49m[43m,[49m[43m [49m[43mvalue[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43membed_dim[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_heads[49m[43m,[49m
[1;32m   1169[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_weight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_bias[49m[43m,[49m
[1;32m   1170[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_k[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_v[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43madd_zero_attn[49m[43m,[49m
[1;32m   1171[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdropout[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mbias[49m[43m,[49m
[1;32m   1172[0m [43m        [49m[43mtraining[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtraining[49m[43m,[49m
[1;32m   1173[0m [43m        [49m[43mkey_padding_mask[49m[38;5;241;43m=[39;49m[43mkey_padding_mask[49m[43m,[49m[43m [49m[43mneed_weights[49m[38;5;241;43m=[39;49m[43mneed_weights[49m[43m,[49m
[1;32m   1174[0m [43m        [49m[43mattn_mask[49m[38;5;241;43m=[39;49m[43mattn_mask[49m[43m,[49m[43m [49m[43maverage_attn_weights[49m[38;5;241;43m=[39;49m[43maverage_attn_weights[49m[43m)[49m
[1;32m   1175[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_first [38;5;129;01mand[39;00m is_batched:
[1;32m   1176[0m     [38;5;28;01mreturn[39;00m attn_output[38;5;241m.[39mtranspose([38;5;241m1[39m, [38;5;241m0[39m), attn_output_weights

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:5161[0m, in [0;36mmulti_head_attention_forward[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)[0m
[1;32m   5159[0m [38;5;28;01melse[39;00m:
[1;32m   5160[0m     attn_output_weights [38;5;241m=[39m torch[38;5;241m.[39mbmm(q_scaled, k[38;5;241m.[39mtranspose([38;5;241m-[39m[38;5;241m2[39m, [38;5;241m-[39m[38;5;241m1[39m))
[0;32m-> 5161[0m attn_output_weights [38;5;241m=[39m [43msoftmax[49m[43m([49m[43mattn_output_weights[49m[43m,[49m[43m [49m[43mdim[49m[38;5;241;43m=[39;49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[1;32m   5162[0m [38;5;28;01mif[39;00m dropout_p [38;5;241m>[39m [38;5;241m0.0[39m:
[1;32m   5163[0m     attn_output_weights [38;5;241m=[39m dropout(attn_output_weights, p[38;5;241m=[39mdropout_p)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:1841[0m, in [0;36msoftmax[0;34m(input, dim, _stacklevel, dtype)[0m
[1;32m   1839[0m     dim [38;5;241m=[39m _get_softmax_dim([38;5;124m"[39m[38;5;124msoftmax[39m[38;5;124m"[39m, [38;5;28minput[39m[38;5;241m.[39mdim(), _stacklevel)
[1;32m   1840[0m [38;5;28;01mif[39;00m dtype [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m-> 1841[0m     ret [38;5;241m=[39m [38;5;28;43minput[39;49m[38;5;241;43m.[39;49m[43msoftmax[49m[43m([49m[43mdim[49m[43m)[49m
[1;32m   1842[0m [38;5;28;01melse[39;00m:
[1;32m   1843[0m     ret [38;5;241m=[39m [38;5;28minput[39m[38;5;241m.[39msoftmax(dim, dtype[38;5;241m=[39mdtype)

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 11.91 GiB total capacity; 8.25 GiB already allocated; 1.74 GiB free; 9.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 16:29:24.091184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 16:29:25.300385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    # x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    # x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    # logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-17 16:29:28 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-17 16:29:28 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-17 16:29:28 INFO [root] [preprocess:100] - --Preprocessing--
----- stderr -----
2024-05-17 16:29:28 INFO [root] [preprocess:101] - [preprocess] preprocessing X_train.shape:(123, 1088, 2), y_train.shape:(123,), X_test.shape:(41, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:29:28 INFO [root] [preprocess:111] - [preprocess] after process X_train.shape:(128, 1088, 2), y_train.shape:(123,), X_test.shape:(64, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:29:28 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([128, 1088, 2]), y_train_task.shape:torch.Size([123]), X_test.shape:torch.Size([64, 1088, 2]), y_test.shape:torch.Size([41])
----- stderr -----
2024-05-17 16:29:28 INFO [root] [<module>:16] - prop:{'batch': 64, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 300, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'nclasses': 3, 'seq_len': 1088, 'input_size': 2, 'device': device(type='cuda')}
----- stderr -----
2024-05-17 16:29:28 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:29:30 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-17 16:29:30 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-17 16:29:30 INFO [root] [attention_sampled_masking_heuristic:142] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-17 16:29:30 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([128, 1088]),index.shape:torch.Size([128, 544])
----- stderr -----
2024-05-17 16:29:30 INFO [root] [random_instance_masking:157] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,indices.shape:(128, 164)
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:29:31 INFO [root] [random_instance_masking:163] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,boolean_indices.shape:(128, 1088),boolean_indices_masked.shape:(128, 1088, 2),boolean_indices_unmasked.shape:(128, 1088, 2)
----- stderr -----
2024-05-17 16:29:31 INFO [root] [random_instance_masking:173] - [random_instance_masking] :X_train_tar.shape:torch.Size([128, 1088, 2]), y_train_tar_masked.shape:torch.Size([128, 328]), y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:29:31 INFO [root] [multitask_train:209] - [multitask_train] X_train_task :torch.Size([128, 1088, 2]),X_train_tar.shape:torch.Size([128, 1088, 2]),y_train_task.shape:torch.Size([123]),y_train_tar_masked.shape:torch.Size([128, 328]),y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:29:31 INFO [root] [multitask_train:221] - [multitask_train] batch:0, num_inst:64, start:0, end:64
----- stderr -----
2024-05-17 16:29:31 INFO [root] [multitask_train:228] - [multitask_train] batch:0,batched_input_tar.shape:torch.Size([64, 1088, 2]),batched_input_task.shape:torch.Size([64, 1088, 2]), batched_boolean_indices_masked.shape:(64, 1088, 2),batched_boolean_indices_unmasked.shape:(64, 1088, 2)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:314[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    308[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    309[0m     
[1;32m    310[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    311[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    312[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 314[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    315[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    316[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    318[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    319[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:229[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    227[0m batched_boolean_indices_unmasked [38;5;241m=[39m boolean_indices_unmasked[start : end]
[1;32m    228[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m,batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 229[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m [43mcompute_tar_loss[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43m\[49m
[1;32m    230[0m [43m    [49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_masked[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_unmasked[49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    232[0m attn, loss_task [38;5;241m=[39m compute_task_loss(prop[[38;5;124m'[39m[38;5;124mnclasses[39m[38;5;124m'[39m], model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_task, y_train_task, \
[1;32m    233[0m     batched_input_task, prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m], num_inst, start)
[1;32m    235[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 

File [0;32m/data4/gsprivate/TARnetWY/utils.py:181[0m, in [0;36mcompute_tar_loss[0;34m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)[0m
[1;32m    178[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_tar_loss[39m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, \
[1;32m    179[0m                     batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start):
[1;32m    180[0m     model[38;5;241m.[39mtrain()
[0;32m--> 181[0m     out_tar [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mreconstruction[39;49m[38;5;124;43m'[39;49m[43m)[49m[[38;5;241m0[39m]
[1;32m    182[0m     logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_tar_loss] out_tar.shape:[39m[38;5;132;01m{[39;00mout_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    183[0m     out_tar_masked [38;5;241m=[39m torch[38;5;241m.[39mas_tensor(out_tar[torch[38;5;241m.[39mas_tensor(batched_boolean_indices_masked)][38;5;241m.[39mreshape(out_tar[38;5;241m.[39mshape[[38;5;241m0[39m], [38;5;241m-[39m[38;5;241m1[39m), device [38;5;241m=[39m device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/multitask_transformer_class.py:118[0m, in [0;36mMultitaskTransformerModel.forward[0;34m(self, x, task_type)[0m
[1;32m    116[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, x, task_type):
[1;32m    117[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtrunk_net(x[38;5;241m.[39mpermute([38;5;241m1[39m, [38;5;241m0[39m, [38;5;241m2[39m))
[0;32m--> 118[0m     x, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtransformer_encoder[49m[43m([49m[43mx[49m[43m)[49m
[1;32m    119[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mbatch_norm(x)
[1;32m    120[0m     [38;5;66;03m# x : seq_len x batch x emb_size[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:125[0m, in [0;36mTransformerEncoder.forward[0;34m(self, src, mask, src_key_padding_mask)[0m
[1;32m    122[0m attn_output [38;5;241m=[39m torch[38;5;241m.[39mzeros((src[38;5;241m.[39mshape[[38;5;241m1[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m]), device [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mdevice) [38;5;66;03m# batch, seq_len, seq_len[39;00m
[1;32m    124[0m [38;5;28;01mfor[39;00m mod [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mlayers:
[0;32m--> 125[0m     output, attn [38;5;241m=[39m [43mmod[49m[43m([49m[43moutput[49m[43m,[49m[43m [49m[43msrc_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mmask[49m[43m,[49m[43m [49m[43msrc_key_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m    126[0m     attn_output [38;5;241m+[39m[38;5;241m=[39m attn
[1;32m    128[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mnorm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:79[0m, in [0;36mTransformerEncoderLayer.forward[0;34m(self, src, src_mask, src_key_padding_mask)[0m
[1;32m     70[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, src, src_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m, src_key_padding_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m):
[1;32m     71[0m [38;5;250m    [39m[38;5;124mr[39m[38;5;124;03m"""Pass the input through the encoder layer.[39;00m
[1;32m     72[0m [38;5;124;03m    Args:[39;00m
[1;32m     73[0m [38;5;124;03m        src: the sequence to the encoder layer (required).[39;00m
[0;32m   (...)[0m
[1;32m     77[0m [38;5;124;03m        see the docs in Transformer class.[39;00m
[1;32m     78[0m [38;5;124;03m    """[39;00m
[0;32m---> 79[0m     src2, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mself_attn[49m[43m([49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43mattn_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_mask[49m[43m,[49m
[1;32m     80[0m [43m                          [49m[43mkey_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m     81[0m     src [38;5;241m=[39m src [38;5;241m+[39m [38;5;28mself[39m[38;5;241m.[39mdropout1(src2)
[1;32m     82[0m     src [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mnorm1(src)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167[0m, in [0;36mMultiheadAttention.forward[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)[0m
[1;32m   1156[0m     attn_output, attn_output_weights [38;5;241m=[39m F[38;5;241m.[39mmulti_head_attention_forward(
[1;32m   1157[0m         query, key, value, [38;5;28mself[39m[38;5;241m.[39membed_dim, [38;5;28mself[39m[38;5;241m.[39mnum_heads,
[1;32m   1158[0m         [38;5;28mself[39m[38;5;241m.[39min_proj_weight, [38;5;28mself[39m[38;5;241m.[39min_proj_bias,
[0;32m   (...)[0m
[1;32m   1164[0m         q_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mq_proj_weight, k_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mk_proj_weight,
[1;32m   1165[0m         v_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mv_proj_weight, average_attn_weights[38;5;241m=[39maverage_attn_weights)
[1;32m   1166[0m [38;5;28;01melse[39;00m:
[0;32m-> 1167[0m     attn_output, attn_output_weights [38;5;241m=[39m [43mF[49m[38;5;241;43m.[39;49m[43mmulti_head_attention_forward[49m[43m([49m
[1;32m   1168[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mkey[49m[43m,[49m[43m [49m[43mvalue[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43membed_dim[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_heads[49m[43m,[49m
[1;32m   1169[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_weight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_bias[49m[43m,[49m
[1;32m   1170[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_k[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_v[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43madd_zero_attn[49m[43m,[49m
[1;32m   1171[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdropout[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mbias[49m[43m,[49m
[1;32m   1172[0m [43m        [49m[43mtraining[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtraining[49m[43m,[49m
[1;32m   1173[0m [43m        [49m[43mkey_padding_mask[49m[38;5;241;43m=[39;49m[43mkey_padding_mask[49m[43m,[49m[43m [49m[43mneed_weights[49m[38;5;241;43m=[39;49m[43mneed_weights[49m[43m,[49m
[1;32m   1174[0m [43m        [49m[43mattn_mask[49m[38;5;241;43m=[39;49m[43mattn_mask[49m[43m,[49m[43m [49m[43maverage_attn_weights[49m[38;5;241;43m=[39;49m[43maverage_attn_weights[49m[43m)[49m
[1;32m   1175[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_first [38;5;129;01mand[39;00m is_batched:
[1;32m   1176[0m     [38;5;28;01mreturn[39;00m attn_output[38;5;241m.[39mtranspose([38;5;241m1[39m, [38;5;241m0[39m), attn_output_weights

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:5161[0m, in [0;36mmulti_head_attention_forward[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)[0m
[1;32m   5159[0m [38;5;28;01melse[39;00m:
[1;32m   5160[0m     attn_output_weights [38;5;241m=[39m torch[38;5;241m.[39mbmm(q_scaled, k[38;5;241m.[39mtranspose([38;5;241m-[39m[38;5;241m2[39m, [38;5;241m-[39m[38;5;241m1[39m))
[0;32m-> 5161[0m attn_output_weights [38;5;241m=[39m [43msoftmax[49m[43m([49m[43mattn_output_weights[49m[43m,[49m[43m [49m[43mdim[49m[38;5;241;43m=[39;49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[1;32m   5162[0m [38;5;28;01mif[39;00m dropout_p [38;5;241m>[39m [38;5;241m0.0[39m:
[1;32m   5163[0m     attn_output_weights [38;5;241m=[39m dropout(attn_output_weights, p[38;5;241m=[39mdropout_p)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:1841[0m, in [0;36msoftmax[0;34m(input, dim, _stacklevel, dtype)[0m
[1;32m   1839[0m     dim [38;5;241m=[39m _get_softmax_dim([38;5;124m"[39m[38;5;124msoftmax[39m[38;5;124m"[39m, [38;5;28minput[39m[38;5;241m.[39mdim(), _stacklevel)
[1;32m   1840[0m [38;5;28;01mif[39;00m dtype [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m-> 1841[0m     ret [38;5;241m=[39m [38;5;28;43minput[39;49m[38;5;241;43m.[39;49m[43msoftmax[49m[43m([49m[43mdim[49m[43m)[49m
[1;32m   1842[0m [38;5;28;01melse[39;00m:
[1;32m   1843[0m     ret [38;5;241m=[39m [38;5;28minput[39m[38;5;241m.[39msoftmax(dim, dtype[38;5;241m=[39mdtype)

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 11.91 GiB total capacity; 8.25 GiB already allocated; 1.74 GiB free; 9.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 16:32:21.475400: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 16:32:22.505861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    # x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    # x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    # logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-17 16:32:25 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-17 16:32:25 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-17 16:32:25 INFO [root] [preprocess:100] - --Preprocessing--
----- stderr -----
2024-05-17 16:32:25 INFO [root] [preprocess:101] - [preprocess] preprocessing X_train.shape:(123, 1088, 2), y_train.shape:(123,), X_test.shape:(41, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:32:25 INFO [root] [preprocess:111] - [preprocess] after process X_train.shape:(128, 1088, 2), y_train.shape:(123,), X_test.shape:(64, 1088, 2), y_test.shape:(41,)
----- stderr -----
2024-05-17 16:32:25 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([128, 1088, 2]), y_train_task.shape:torch.Size([123]), X_test.shape:torch.Size([64, 1088, 2]), y_test.shape:torch.Size([41])
----- stderr -----
2024-05-17 16:32:25 INFO [root] [<module>:16] - prop:{'batch': 64, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 300, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'nclasses': 3, 'seq_len': 1088, 'input_size': 2, 'device': device(type='cuda')}
----- stderr -----
2024-05-17 16:32:25 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:32:27 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-17 16:32:27 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-17 16:32:27 INFO [root] [attention_sampled_masking_heuristic:142] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-17 16:32:27 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([128, 1088]),index.shape:torch.Size([128, 544])
----- stderr -----
2024-05-17 16:32:27 INFO [root] [random_instance_masking:157] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,indices.shape:(128, 164)
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:1088,
----- stderr -----
2024-05-17 16:32:28 INFO [root] [random_instance_masking:163] - [random_instance_masking]: X.shape:torch.Size([128, 1088, 2]) ,boolean_indices.shape:(128, 1088),boolean_indices_masked.shape:(128, 1088, 2),boolean_indices_unmasked.shape:(128, 1088, 2)
----- stderr -----
2024-05-17 16:32:28 INFO [root] [random_instance_masking:173] - [random_instance_masking] :X_train_tar.shape:torch.Size([128, 1088, 2]), y_train_tar_masked.shape:torch.Size([128, 328]), y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:32:28 INFO [root] [multitask_train:209] - [multitask_train] X_train_task :torch.Size([128, 1088, 2]),X_train_tar.shape:torch.Size([128, 1088, 2]),y_train_task.shape:torch.Size([123]),y_train_tar_masked.shape:torch.Size([128, 328]),y_train_tar_unmasked.shape:torch.Size([128, 1848])
----- stderr -----
2024-05-17 16:32:28 INFO [root] [multitask_train:221] - [multitask_train] batch:0, num_inst:64, start:0, end:64
----- stderr -----
2024-05-17 16:32:28 INFO [root] [multitask_train:228] - [multitask_train] batch:0,batched_input_tar.shape:torch.Size([64, 1088, 2]),batched_input_task.shape:torch.Size([64, 1088, 2]), batched_boolean_indices_masked.shape:(64, 1088, 2),batched_boolean_indices_unmasked.shape:(64, 1088, 2)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:314[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    308[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    309[0m     
[1;32m    310[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    311[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    312[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 314[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    315[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    316[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    318[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    319[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:229[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    227[0m batched_boolean_indices_unmasked [38;5;241m=[39m boolean_indices_unmasked[start : end]
[1;32m    228[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m,batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 229[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m [43mcompute_tar_loss[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43m\[49m
[1;32m    230[0m [43m    [49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_masked[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_unmasked[49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    232[0m attn, loss_task [38;5;241m=[39m compute_task_loss(prop[[38;5;124m'[39m[38;5;124mnclasses[39m[38;5;124m'[39m], model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_task, y_train_task, \
[1;32m    233[0m     batched_input_task, prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m], num_inst, start)
[1;32m    235[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 

File [0;32m/data4/gsprivate/TARnetWY/utils.py:181[0m, in [0;36mcompute_tar_loss[0;34m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)[0m
[1;32m    178[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_tar_loss[39m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, \
[1;32m    179[0m                     batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start):
[1;32m    180[0m     model[38;5;241m.[39mtrain()
[0;32m--> 181[0m     out_tar [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mreconstruction[39;49m[38;5;124;43m'[39;49m[43m)[49m[[38;5;241m0[39m]
[1;32m    182[0m     logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_tar_loss] out_tar.shape:[39m[38;5;132;01m{[39;00mout_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    183[0m     out_tar_masked [38;5;241m=[39m torch[38;5;241m.[39mas_tensor(out_tar[torch[38;5;241m.[39mas_tensor(batched_boolean_indices_masked)][38;5;241m.[39mreshape(out_tar[38;5;241m.[39mshape[[38;5;241m0[39m], [38;5;241m-[39m[38;5;241m1[39m), device [38;5;241m=[39m device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/multitask_transformer_class.py:118[0m, in [0;36mMultitaskTransformerModel.forward[0;34m(self, x, task_type)[0m
[1;32m    116[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, x, task_type):
[1;32m    117[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtrunk_net(x[38;5;241m.[39mpermute([38;5;241m1[39m, [38;5;241m0[39m, [38;5;241m2[39m))
[0;32m--> 118[0m     x, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtransformer_encoder[49m[43m([49m[43mx[49m[43m)[49m
[1;32m    119[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mbatch_norm(x)
[1;32m    120[0m     [38;5;66;03m# x : seq_len x batch x emb_size[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:125[0m, in [0;36mTransformerEncoder.forward[0;34m(self, src, mask, src_key_padding_mask)[0m
[1;32m    122[0m attn_output [38;5;241m=[39m torch[38;5;241m.[39mzeros((src[38;5;241m.[39mshape[[38;5;241m1[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m]), device [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mdevice) [38;5;66;03m# batch, seq_len, seq_len[39;00m
[1;32m    124[0m [38;5;28;01mfor[39;00m mod [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mlayers:
[0;32m--> 125[0m     output, attn [38;5;241m=[39m [43mmod[49m[43m([49m[43moutput[49m[43m,[49m[43m [49m[43msrc_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mmask[49m[43m,[49m[43m [49m[43msrc_key_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m    126[0m     attn_output [38;5;241m+[39m[38;5;241m=[39m attn
[1;32m    128[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mnorm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:79[0m, in [0;36mTransformerEncoderLayer.forward[0;34m(self, src, src_mask, src_key_padding_mask)[0m
[1;32m     70[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, src, src_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m, src_key_padding_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m):
[1;32m     71[0m [38;5;250m    [39m[38;5;124mr[39m[38;5;124;03m"""Pass the input through the encoder layer.[39;00m
[1;32m     72[0m [38;5;124;03m    Args:[39;00m
[1;32m     73[0m [38;5;124;03m        src: the sequence to the encoder layer (required).[39;00m
[0;32m   (...)[0m
[1;32m     77[0m [38;5;124;03m        see the docs in Transformer class.[39;00m
[1;32m     78[0m [38;5;124;03m    """[39;00m
[0;32m---> 79[0m     src2, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mself_attn[49m[43m([49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43mattn_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_mask[49m[43m,[49m
[1;32m     80[0m [43m                          [49m[43mkey_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m     81[0m     src [38;5;241m=[39m src [38;5;241m+[39m [38;5;28mself[39m[38;5;241m.[39mdropout1(src2)
[1;32m     82[0m     src [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mnorm1(src)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167[0m, in [0;36mMultiheadAttention.forward[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)[0m
[1;32m   1156[0m     attn_output, attn_output_weights [38;5;241m=[39m F[38;5;241m.[39mmulti_head_attention_forward(
[1;32m   1157[0m         query, key, value, [38;5;28mself[39m[38;5;241m.[39membed_dim, [38;5;28mself[39m[38;5;241m.[39mnum_heads,
[1;32m   1158[0m         [38;5;28mself[39m[38;5;241m.[39min_proj_weight, [38;5;28mself[39m[38;5;241m.[39min_proj_bias,
[0;32m   (...)[0m
[1;32m   1164[0m         q_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mq_proj_weight, k_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mk_proj_weight,
[1;32m   1165[0m         v_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mv_proj_weight, average_attn_weights[38;5;241m=[39maverage_attn_weights)
[1;32m   1166[0m [38;5;28;01melse[39;00m:
[0;32m-> 1167[0m     attn_output, attn_output_weights [38;5;241m=[39m [43mF[49m[38;5;241;43m.[39;49m[43mmulti_head_attention_forward[49m[43m([49m
[1;32m   1168[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mkey[49m[43m,[49m[43m [49m[43mvalue[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43membed_dim[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_heads[49m[43m,[49m
[1;32m   1169[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_weight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_bias[49m[43m,[49m
[1;32m   1170[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_k[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_v[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43madd_zero_attn[49m[43m,[49m
[1;32m   1171[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdropout[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mbias[49m[43m,[49m
[1;32m   1172[0m [43m        [49m[43mtraining[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtraining[49m[43m,[49m
[1;32m   1173[0m [43m        [49m[43mkey_padding_mask[49m[38;5;241;43m=[39;49m[43mkey_padding_mask[49m[43m,[49m[43m [49m[43mneed_weights[49m[38;5;241;43m=[39;49m[43mneed_weights[49m[43m,[49m
[1;32m   1174[0m [43m        [49m[43mattn_mask[49m[38;5;241;43m=[39;49m[43mattn_mask[49m[43m,[49m[43m [49m[43maverage_attn_weights[49m[38;5;241;43m=[39;49m[43maverage_attn_weights[49m[43m)[49m
[1;32m   1175[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_first [38;5;129;01mand[39;00m is_batched:
[1;32m   1176[0m     [38;5;28;01mreturn[39;00m attn_output[38;5;241m.[39mtranspose([38;5;241m1[39m, [38;5;241m0[39m), attn_output_weights

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:5161[0m, in [0;36mmulti_head_attention_forward[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)[0m
[1;32m   5159[0m [38;5;28;01melse[39;00m:
[1;32m   5160[0m     attn_output_weights [38;5;241m=[39m torch[38;5;241m.[39mbmm(q_scaled, k[38;5;241m.[39mtranspose([38;5;241m-[39m[38;5;241m2[39m, [38;5;241m-[39m[38;5;241m1[39m))
[0;32m-> 5161[0m attn_output_weights [38;5;241m=[39m [43msoftmax[49m[43m([49m[43mattn_output_weights[49m[43m,[49m[43m [49m[43mdim[49m[38;5;241;43m=[39;49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[1;32m   5162[0m [38;5;28;01mif[39;00m dropout_p [38;5;241m>[39m [38;5;241m0.0[39m:
[1;32m   5163[0m     attn_output_weights [38;5;241m=[39m dropout(attn_output_weights, p[38;5;241m=[39mdropout_p)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:1841[0m, in [0;36msoftmax[0;34m(input, dim, _stacklevel, dtype)[0m
[1;32m   1839[0m     dim [38;5;241m=[39m _get_softmax_dim([38;5;124m"[39m[38;5;124msoftmax[39m[38;5;124m"[39m, [38;5;28minput[39m[38;5;241m.[39mdim(), _stacklevel)
[1;32m   1840[0m [38;5;28;01mif[39;00m dtype [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m-> 1841[0m     ret [38;5;241m=[39m [38;5;28;43minput[39;49m[38;5;241;43m.[39;49m[43msoftmax[49m[43m([49m[43mdim[49m[43m)[49m
[1;32m   1842[0m [38;5;28;01melse[39;00m:
[1;32m   1843[0m     ret [38;5;241m=[39m [38;5;28minput[39m[38;5;241m.[39msoftmax(dim, dtype[38;5;241m=[39mdtype)

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 11.91 GiB total capacity; 8.25 GiB already allocated; 1.74 GiB free; 9.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 16:35:21.846009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 16:35:22.811812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-17 17:28:06.658803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-17 17:28:08.233728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Writing 43539995 bytes to multi-geng.nbconvert.ipynb
[NbConvertApp] Writing 43576962 bytes to multi-geng.nbconvert.ipynb
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-18 04:45:49.374695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-18 04:45:50.888104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Writing 290692410 bytes to multi-geng.nbconvert.ipynb
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-18 11:15:18.650854: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-18 11:15:23.326483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-18 11:15:34 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-18 11:15:34 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-18 11:15:34 INFO [root] [<module>:8] - After slicing : x_train_sliced.shape:(1230, 800, 2), y_train_sliced.shape:(1230,), x_val_sliced.shape:(410, 800, 2), y_val_sliced.shape:(410,)
----- stderr -----
2024-05-18 11:15:34 INFO [root] [preprocess:103] - --Preprocessing--
----- stderr -----
2024-05-18 11:15:34 INFO [root] [preprocess:104] - [preprocess] preprocessing X_train.shape:(1230, 800, 2), y_train.shape:(1230,), X_test.shape:(410, 800, 2), y_test.shape:(410,)
----- stderr -----
2024-05-18 11:15:34 INFO [root] [preprocess:115] - [preprocess] after process X_train.shape:(1248, 800, 2), y_train.shape:(1230,), X_test.shape:(416, 800, 2), y_test.shape:(410,)
----- stderr -----
2024-05-18 11:15:34 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([1248, 800, 2]), y_train_task.shape:torch.Size([1230]), X_test.shape:torch.Size([416, 800, 2]), y_test.shape:torch.Size([410])
----- stderr -----
2024-05-18 11:15:34 INFO [root] [<module>:16] - prop:{'batch': 32, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 250, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'accumulation_steps': 2, 'nclasses': 3, 'seq_len': 800, 'input_size': 2, 'device': device(type='cuda')}
----- stderr -----
2024-05-18 11:15:34 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:32,seq_len:800,
----- stderr -----
2024-05-18 11:15:41 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-18 11:15:41 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-18 11:15:41 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-18 11:15:41 INFO [root] [attention_sampled_masking_heuristic:150] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([1248, 800]),index.shape:torch.Size([1248, 400])
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:32,seq_len:800,
----- stderr -----
2024-05-18 11:15:41 INFO [root] [random_instance_masking:161] - [random_instance_masking]: X.shape:torch.Size([1248, 800, 2]) ,indices.shape:(1248, 120)
----- stderr -----
2024-05-18 11:15:45 INFO [root] [random_instance_masking:167] - [random_instance_masking]: X.shape:torch.Size([1248, 800, 2]) ,boolean_indices.shape:(1248, 800),boolean_indices_masked.shape:(1248, 800, 2),boolean_indices_unmasked.shape:(1248, 800, 2)
----- stderr -----
2024-05-18 11:15:45 INFO [root] [random_instance_masking:177] - [random_instance_masking] :X_train_tar.shape:torch.Size([1248, 800, 2]), y_train_tar_masked.shape:torch.Size([1248, 240]), y_train_tar_unmasked.shape:torch.Size([1248, 1360])
----- stderr -----
2024-05-18 11:15:45 INFO [root] [multitask_train:221] - [multitask_train] accumulation_steps:2, X_train_tar.shape:torch.Size([1248, 800, 2]), X_train_task.shape:torch.Size([1248, 800, 2]), y_train_tar_masked.shape:torch.Size([1248, 240]), y_train_tar_unmasked.shape:torch.Size([1248, 1360]), y_train_task.shape:torch.Size([1230])
----- stderr -----
2024-05-18 11:15:45 INFO [root] [multitask_train:233] - [multitask_train] batch:0, num_inst:32, start:0, end:32
----- stderr -----
2024-05-18 11:15:45 INFO [root] [multitask_train:238] - [multitask_train] batch:0, batched_input_tar.shape:torch.Size([32, 800, 2]), batched_input_task.shape:torch.Size([32, 800, 2]), batched_boolean_indices_masked.shape:(32, 800, 2), batched_boolean_indices_unmasked.shape:(32, 800, 2)
----- stderr -----
2024-05-18 11:15:47 INFO [root] [compute_tar_loss:186] - [compute_tar_loss] out_tar.shape:torch.Size([32, 800, 2])
----- stderr -----
2024-05-18 11:15:47 INFO [root] [compute_tar_loss:189] - [compute_tar_loss] out_tar_masked.shape:torch.Size([32, 240])
----- stderr -----
2024-05-18 11:15:47 INFO [root] [compute_tar_loss:192] - [compute_tar_loss] loss_tar_unmasked:1.9835259914398193,loss_tar_masked:2.2194278240203857
----- stderr -----
2024-05-18 11:15:47 INFO [root] [compute_task_loss:198] - [compute_task_loss]: criterion_task:CrossEntropyLoss(), y_train_task.shape:torch.Size([1230]), batched_input_task.shape:torch.Size([32, 800, 2]), task_type:classification, num_inst:32, start:0
----- stderr -----
2024-05-18 11:15:48 INFO [root] [compute_task_loss:201] - [compute_task_loss]:out_task.shape:torch.Size([32, 3]),out_task[0]:tensor([ 0.1602, -1.8206, -0.0304], device='cuda:0', grad_fn=<SelectBackward0>)
----- stderr -----
2024-05-18 11:15:48 INFO [root] [compute_task_loss:203] - [compute_task_loss]:after change out_task.shape: torch.Size([32, 3])
----- stderr -----
2024-05-18 11:15:48 INFO [root] [compute_task_loss:204] - [compute_task_loss] out_task[ : num_inst].shape:torch.Size([32, 3]), y_train_task[start : start + num_inst].shape:torch.Size([32])
----- stderr -----
2024-05-18 11:15:48 INFO [root] [compute_task_loss:206] - [compute_task_loss] loss_task:0.9976714253425598,attn.shape:torch.Size([32, 800, 800])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:321[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    315[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    316[0m     
[1;32m    317[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    318[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    319[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 321[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    322[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    323[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    325[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    326[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:252[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    250[0m loss [38;5;241m=[39m prop[[38;5;124m'[39m[38;5;124mtask_rate[39m[38;5;124m'[39m] [38;5;241m*[39m (prop[[38;5;124m'[39m[38;5;124mlamb[39m[38;5;124m'[39m] [38;5;241m*[39m loss_tar_masked [38;5;241m+[39m ([38;5;241m1[39m [38;5;241m-[39m prop[[38;5;124m'[39m[38;5;124mlamb[39m[38;5;124m'[39m]) [38;5;241m*[39m loss_tar_unmasked) [38;5;241m+[39m ([38;5;241m1[39m [38;5;241m-[39m prop[[38;5;124m'[39m[38;5;124mtask_rate[39m[38;5;124m'[39m]) [38;5;241m*[39m loss_task
[1;32m    251[0m loss [38;5;241m=[39m loss [38;5;241m/[39m accumulation_steps
[0;32m--> 252[0m [43mloss[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m[43m)[49m
[1;32m    254[0m [38;5;28;01mif[39;00m (i [38;5;241m+[39m [38;5;241m1[39m) [38;5;241m%[39m accumulation_steps [38;5;241m==[39m [38;5;241m0[39m [38;5;129;01mor[39;00m (i [38;5;241m+[39m [38;5;241m1[39m) [38;5;241m==[39m num_batches:
[1;32m    255[0m     optimizer[38;5;241m.[39mstep()

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/_tensor.py:488[0m, in [0;36mTensor.backward[0;34m(self, gradient, retain_graph, create_graph, inputs)[0m
[1;32m    478[0m [38;5;28;01mif[39;00m has_torch_function_unary([38;5;28mself[39m):
[1;32m    479[0m     [38;5;28;01mreturn[39;00m handle_torch_function(
[1;32m    480[0m         Tensor[38;5;241m.[39mbackward,
[1;32m    481[0m         ([38;5;28mself[39m,),
[0;32m   (...)[0m
[1;32m    486[0m         inputs[38;5;241m=[39minputs,
[1;32m    487[0m     )
[0;32m--> 488[0m [43mtorch[49m[38;5;241;43m.[39;49m[43mautograd[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m
[1;32m    489[0m [43m    [49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43mgradient[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[38;5;241;43m=[39;49m[43minputs[49m
[1;32m    490[0m [43m[49m[43m)[49m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/autograd/__init__.py:197[0m, in [0;36mbackward[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)[0m
[1;32m    192[0m     retain_graph [38;5;241m=[39m create_graph
[1;32m    194[0m [38;5;66;03m# The reason we repeat same the comment below is that[39;00m
[1;32m    195[0m [38;5;66;03m# some Python versions print out the first line of a multi-line function[39;00m
[1;32m    196[0m [38;5;66;03m# calls in the traceback and some print out the last line[39;00m
[0;32m--> 197[0m [43mVariable[49m[38;5;241;43m.[39;49m[43m_execution_engine[49m[38;5;241;43m.[39;49m[43mrun_backward[49m[43m([49m[43m  [49m[38;5;66;43;03m# Calls into the C++ engine to run the backward pass[39;49;00m
[1;32m    198[0m [43m    [49m[43mtensors[49m[43m,[49m[43m [49m[43mgrad_tensors_[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[43m,[49m
[1;32m    199[0m [43m    [49m[43mallow_unreachable[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m[43m [49m[43maccumulate_grad[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 626.00 MiB (GPU 0; 11.91 GiB total capacity; 6.40 GiB already allocated; 526.06 MiB free; 6.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-18 11:16:54.670672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-18 11:16:55.624554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Writing 128825977 bytes to multi-geng.nbconvert.ipynb
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:03:21.033677: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:03:24.851158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-19 03:03:34 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-19 03:03:34 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-19 03:03:34 INFO [root] [<module>:8] - After slicing : x_train_sliced.shape:(1230, 800, 2), y_train_sliced.shape:(1230,), x_val_sliced.shape:(410, 800, 2), y_val_sliced.shape:(410,)
----- stderr -----
2024-05-19 03:03:34 INFO [root] [preprocess:103] - --Preprocessing--
----- stderr -----
2024-05-19 03:03:34 INFO [root] [preprocess:104] - [preprocess] preprocessing X_train.shape:(1230, 800, 2), y_train.shape:(1230,), X_test.shape:(410, 800, 2), y_test.shape:(410,)
----- stderr -----
2024-05-19 03:03:35 INFO [root] [preprocess:115] - [preprocess] after process X_train.shape:(1280, 800, 2), y_train.shape:(1230,), X_test.shape:(448, 800, 2), y_test.shape:(410,)
----- stderr -----
2024-05-19 03:03:35 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([1280, 800, 2]), y_train_task.shape:torch.Size([1230]), X_test.shape:torch.Size([448, 800, 2]), y_test.shape:torch.Size([410])
----- stderr -----
2024-05-19 03:03:35 INFO [root] [<module>:16] - prop:{'batch': 64, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 250, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'accumulation_steps': 1, 'nclasses': 3, 'seq_len': 800, 'input_size': 2, 'device': device(type='cuda')}
----- stderr -----
2024-05-19 03:03:35 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:800,
----- stderr -----
2024-05-19 03:03:42 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-19 03:03:42 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-19 03:03:42 INFO [root] [attention_sampled_masking_heuristic:146] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-19 03:03:42 INFO [root] [attention_sampled_masking_heuristic:150] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([1280, 800]),index.shape:torch.Size([1280, 400])
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:64,seq_len:800,
----- stderr -----
2024-05-19 03:03:42 INFO [root] [random_instance_masking:161] - [random_instance_masking]: X.shape:torch.Size([1280, 800, 2]) ,indices.shape:(1280, 120)
----- stderr -----
2024-05-19 03:03:46 INFO [root] [random_instance_masking:167] - [random_instance_masking]: X.shape:torch.Size([1280, 800, 2]) ,boolean_indices.shape:(1280, 800),boolean_indices_masked.shape:(1280, 800, 2),boolean_indices_unmasked.shape:(1280, 800, 2)
----- stderr -----
2024-05-19 03:03:46 INFO [root] [random_instance_masking:177] - [random_instance_masking] :X_train_tar.shape:torch.Size([1280, 800, 2]), y_train_tar_masked.shape:torch.Size([1280, 240]), y_train_tar_unmasked.shape:torch.Size([1280, 1360])
----- stderr -----
2024-05-19 03:03:46 INFO [root] [multitask_train:221] - [multitask_train] accumulation_steps:1, X_train_tar.shape:torch.Size([1280, 800, 2]), X_train_task.shape:torch.Size([1280, 800, 2]), y_train_tar_masked.shape:torch.Size([1280, 240]), y_train_tar_unmasked.shape:torch.Size([1280, 1360]), y_train_task.shape:torch.Size([1230])
----- stderr -----
2024-05-19 03:03:46 INFO [root] [multitask_train:233] - [multitask_train] batch:0, num_inst:64, start:0, end:64
----- stderr -----
2024-05-19 03:03:46 INFO [root] [multitask_train:238] - [multitask_train] batch:0, batched_input_tar.shape:torch.Size([64, 800, 2]), batched_input_task.shape:torch.Size([64, 800, 2]), batched_boolean_indices_masked.shape:(64, 800, 2), batched_boolean_indices_unmasked.shape:(64, 800, 2)
----- stderr -----
2024-05-19 03:03:46 INFO [root] [forward:118] - ---MultitaskTransformerModel forward---
----- stderr -----
2024-05-19 03:03:46 INFO [root] [forward:119] - [MultitaskTransformerModel] x.shape:torch.Size([64, 800, 2])
----- stderr -----
2024-05-19 03:03:49 INFO [root] [forward:121] - [MultitaskTransformerModel] x.shape after Trunk_net:torch.Size([800, 64, 64])
----- stderr -----
2024-05-19 03:03:49 INFO [root] [compute_tar_loss:186] - [compute_tar_loss] out_tar.shape:torch.Size([64, 800, 2])
----- stderr -----
2024-05-19 03:03:49 INFO [root] [compute_tar_loss:189] - [compute_tar_loss] out_tar_masked.shape:torch.Size([64, 240])
----- stderr -----
2024-05-19 03:03:49 INFO [root] [compute_tar_loss:192] - [compute_tar_loss] loss_tar_unmasked:2.057732343673706,loss_tar_masked:2.1526973247528076
----- stderr -----
2024-05-19 03:03:49 INFO [root] [compute_task_loss:198] - [compute_task_loss]: criterion_task:CrossEntropyLoss(), y_train_task.shape:torch.Size([1230]), batched_input_task.shape:torch.Size([64, 800, 2]), task_type:classification, num_inst:64, start:0
----- stderr -----
2024-05-19 03:03:49 INFO [root] [forward:118] - ---MultitaskTransformerModel forward---
----- stderr -----
2024-05-19 03:03:49 INFO [root] [forward:119] - [MultitaskTransformerModel] x.shape:torch.Size([64, 800, 2])
----- stderr -----
2024-05-19 03:03:49 INFO [root] [forward:121] - [MultitaskTransformerModel] x.shape after Trunk_net:torch.Size([800, 64, 64])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mOutOfMemoryError[0m                          Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:325[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    319[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    320[0m     
[1;32m    321[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    322[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    323[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 325[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    326[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    327[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    329[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    330[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:243[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    238[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m, batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    240[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m compute_tar_loss(model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_tar, y_train_tar_masked, y_train_tar_unmasked, 
[1;32m    241[0m     batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)
[0;32m--> 243[0m attn, loss_task [38;5;241m=[39m [43mcompute_task_loss[49m[43m([49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mnclasses[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    244[0m [43m    [49m[43mbatched_input_task[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mtask_type[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    246[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 
[1;32m    247[0m total_loss_tar_unmasked [38;5;241m+[39m[38;5;241m=[39m loss_tar_unmasked[38;5;241m.[39mitem()

File [0;32m/data4/gsprivate/TARnetWY/utils.py:200[0m, in [0;36mcompute_task_loss[0;34m(nclasses, model, device, criterion_task, y_train_task, batched_input_task, task_type, num_inst, start)[0m
[1;32m    198[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_task_loss]: criterion_task:[39m[38;5;132;01m{[39;00mcriterion_task[38;5;132;01m}[39;00m[38;5;124m, y_train_task.shape:[39m[38;5;132;01m{[39;00my_train_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, task_type:[39m[38;5;132;01m{[39;00mtask_type[38;5;132;01m}[39;00m[38;5;124m, num_inst:[39m[38;5;132;01m{[39;00mnum_inst[38;5;132;01m}[39;00m[38;5;124m, start:[39m[38;5;132;01m{[39;00mstart[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    199[0m model[38;5;241m.[39mtrain()
[0;32m--> 200[0m out_task, attn [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_task[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[43mtask_type[49m[43m)[49m
[1;32m    201[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_task_loss]:out_task.shape:[39m[38;5;132;01m{[39;00mout_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m,out_task[0]:[39m[38;5;132;01m{[39;00mout_task[[38;5;241m0[39m][38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    202[0m out_task [38;5;241m=[39m out_task[38;5;241m.[39mview([38;5;241m-[39m[38;5;241m1[39m, nclasses) [38;5;28;01mif[39;00m task_type [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m [38;5;28;01melse[39;00m out_task[38;5;241m.[39msqueeze()

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/multitask_transformer_class.py:123[0m, in [0;36mMultitaskTransformerModel.forward[0;34m(self, x, task_type)[0m
[1;32m    120[0m x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtrunk_net(x[38;5;241m.[39mpermute([38;5;241m1[39m, [38;5;241m0[39m, [38;5;241m2[39m))
[1;32m    121[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[MultitaskTransformerModel] x.shape after Trunk_net:[39m[38;5;132;01m{[39;00mx[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 123[0m x, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtransformer_encoder[49m[43m([49m[43mx[49m[43m)[49m
[1;32m    124[0m x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mbatch_norm(x)
[1;32m    125[0m [38;5;66;03m# x : seq_len x batch x emb_size[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:125[0m, in [0;36mTransformerEncoder.forward[0;34m(self, src, mask, src_key_padding_mask)[0m
[1;32m    122[0m attn_output [38;5;241m=[39m torch[38;5;241m.[39mzeros((src[38;5;241m.[39mshape[[38;5;241m1[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m], src[38;5;241m.[39mshape[[38;5;241m0[39m]), device [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mdevice) [38;5;66;03m# batch, seq_len, seq_len[39;00m
[1;32m    124[0m [38;5;28;01mfor[39;00m mod [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mlayers:
[0;32m--> 125[0m     output, attn [38;5;241m=[39m [43mmod[49m[43m([49m[43moutput[49m[43m,[49m[43m [49m[43msrc_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mmask[49m[43m,[49m[43m [49m[43msrc_key_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m    126[0m     attn_output [38;5;241m+[39m[38;5;241m=[39m attn
[1;32m    128[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mnorm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/gsprivate/TARnetWY/transformer.py:79[0m, in [0;36mTransformerEncoderLayer.forward[0;34m(self, src, src_mask, src_key_padding_mask)[0m
[1;32m     70[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, src, src_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m, src_key_padding_mask [38;5;241m=[39m [38;5;28;01mNone[39;00m):
[1;32m     71[0m [38;5;250m    [39m[38;5;124mr[39m[38;5;124;03m"""Pass the input through the encoder layer.[39;00m
[1;32m     72[0m [38;5;124;03m    Args:[39;00m
[1;32m     73[0m [38;5;124;03m        src: the sequence to the encoder layer (required).[39;00m
[0;32m   (...)[0m
[1;32m     77[0m [38;5;124;03m        see the docs in Transformer class.[39;00m
[1;32m     78[0m [38;5;124;03m    """[39;00m
[0;32m---> 79[0m     src2, attn [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mself_attn[49m[43m([49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43msrc[49m[43m,[49m[43m [49m[43mattn_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_mask[49m[43m,[49m
[1;32m     80[0m [43m                          [49m[43mkey_padding_mask[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43msrc_key_padding_mask[49m[43m)[49m
[1;32m     81[0m     src [38;5;241m=[39m src [38;5;241m+[39m [38;5;28mself[39m[38;5;241m.[39mdropout1(src2)
[1;32m     82[0m     src [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mnorm1(src)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/activation.py:1167[0m, in [0;36mMultiheadAttention.forward[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)[0m
[1;32m   1156[0m     attn_output, attn_output_weights [38;5;241m=[39m F[38;5;241m.[39mmulti_head_attention_forward(
[1;32m   1157[0m         query, key, value, [38;5;28mself[39m[38;5;241m.[39membed_dim, [38;5;28mself[39m[38;5;241m.[39mnum_heads,
[1;32m   1158[0m         [38;5;28mself[39m[38;5;241m.[39min_proj_weight, [38;5;28mself[39m[38;5;241m.[39min_proj_bias,
[0;32m   (...)[0m
[1;32m   1164[0m         q_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mq_proj_weight, k_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mk_proj_weight,
[1;32m   1165[0m         v_proj_weight[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mv_proj_weight, average_attn_weights[38;5;241m=[39maverage_attn_weights)
[1;32m   1166[0m [38;5;28;01melse[39;00m:
[0;32m-> 1167[0m     attn_output, attn_output_weights [38;5;241m=[39m [43mF[49m[38;5;241;43m.[39;49m[43mmulti_head_attention_forward[49m[43m([49m
[1;32m   1168[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mkey[49m[43m,[49m[43m [49m[43mvalue[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43membed_dim[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_heads[49m[43m,[49m
[1;32m   1169[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_weight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43min_proj_bias[49m[43m,[49m
[1;32m   1170[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_k[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias_v[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43madd_zero_attn[49m[43m,[49m
[1;32m   1171[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdropout[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mout_proj[49m[38;5;241;43m.[39;49m[43mbias[49m[43m,[49m
[1;32m   1172[0m [43m        [49m[43mtraining[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtraining[49m[43m,[49m
[1;32m   1173[0m [43m        [49m[43mkey_padding_mask[49m[38;5;241;43m=[39;49m[43mkey_padding_mask[49m[43m,[49m[43m [49m[43mneed_weights[49m[38;5;241;43m=[39;49m[43mneed_weights[49m[43m,[49m
[1;32m   1174[0m [43m        [49m[43mattn_mask[49m[38;5;241;43m=[39;49m[43mattn_mask[49m[43m,[49m[43m [49m[43maverage_attn_weights[49m[38;5;241;43m=[39;49m[43maverage_attn_weights[49m[43m)[49m
[1;32m   1175[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_first [38;5;129;01mand[39;00m is_batched:
[1;32m   1176[0m     [38;5;28;01mreturn[39;00m attn_output[38;5;241m.[39mtranspose([38;5;241m1[39m, [38;5;241m0[39m), attn_output_weights

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py:5160[0m, in [0;36mmulti_head_attention_forward[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)[0m
[1;32m   5158[0m     attn_output_weights [38;5;241m=[39m torch[38;5;241m.[39mbaddbmm(attn_mask, q_scaled, k[38;5;241m.[39mtranspose([38;5;241m-[39m[38;5;241m2[39m, [38;5;241m-[39m[38;5;241m1[39m))
[1;32m   5159[0m [38;5;28;01melse[39;00m:
[0;32m-> 5160[0m     attn_output_weights [38;5;241m=[39m [43mtorch[49m[38;5;241;43m.[39;49m[43mbmm[49m[43m([49m[43mq_scaled[49m[43m,[49m[43m [49m[43mk[49m[38;5;241;43m.[39;49m[43mtranspose[49m[43m([49m[38;5;241;43m-[39;49m[38;5;241;43m2[39;49m[43m,[49m[43m [49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m[43m)[49m
[1;32m   5161[0m attn_output_weights [38;5;241m=[39m softmax(attn_output_weights, dim[38;5;241m=[39m[38;5;241m-[39m[38;5;241m1[39m)
[1;32m   5162[0m [38;5;28;01mif[39;00m dropout_p [38;5;241m>[39m [38;5;241m0.0[39m:

[0;31mOutOfMemoryError[0m: CUDA out of memory. Tried to allocate 1.22 GiB (GPU 0; 11.91 GiB total capacity; 9.27 GiB already allocated; 1.03 GiB free; 10.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:04:54.470779: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:04:57.374456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:25:34.845701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:25:37.603513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:27:38.064252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:27:41.205966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
metric = []
for x_train_fold, y_train_fold, x_val_fold, y_val_fold in k_splits:
    logging.info(f"\n---fold:{idx}---")
    logging.info(f"x_train_fold.shape:{x_train_fold.shape}, y_train_fold.shape:{y_train_fold.shape}, x_val_fold.shape:{x_val_fold.shape}, y_val_fold.shape:{y_val_fold.shape}")
    # Slice the data
    x_train_fold, y_train_fold = geng.slice_time_series(x_train_fold, y_train_fold, window_size, step_size)
    x_val_fold, y_val_fold = geng.slice_time_series(x_val_fold, y_val_fold, window_size, step_size)
    logging.info(f"After slicing : x_train_sliced.shape:{x_train_fold.shape}, y_train_sliced.shape:{y_train_fold.shape}, x_val_sliced.shape:{x_val_fold.shape}, y_val_sliced.shape:{y_val_fold.shape}")
    
    X_train_task, y_train_task, X_test, y_test = utils.preprocess(prop, x_train_fold, y_train_fold, x_val_fold, y_val_fold)
    logging.info(f"After preprocess : X_train_task.shape:{X_train_task.shape}, y_train_task.shape:{y_train_task.shape}, X_test.shape:{ X_test.shape}, y_test.shape:{y_test.shape}")
    
    prop['nclasses'] = torch.max(y_train_task).item() + 1 if prop['task_type'] == 'classification' else None
    prop['dataset'], prop['seq_len'], prop['input_size'] = prop['dataset'], X_train_task.shape[1], X_train_task.shape[2]
    prop['device'] = torch.device('cuda' if torch.cuda.is_available() else "cpu")
    logging.info(f"prop:{prop}")

    logging.info('Initializing model...')
    model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer = utils.initialize_training(prop)
    logging.info('Model initialized...')

    logging.info('Training start...')
    acc , rmse, mae  = utils.training(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)
    logging.info('Training complete...')
    
    if prop['task_type'] == 'classification':
        metric.append(f"Fold {idx} : acc:{acc}")
    else:
        metric.append(f"Fold {idx} : rmse:{rmse}, mae:{mae}")
    idx += 1

for m in metric:
    logging.info(m)
------------------

----- stderr -----
2024-05-19 03:27:46 INFO [root] [<module>:3] - 
---fold:1---
----- stderr -----
2024-05-19 03:27:46 INFO [root] [<module>:4] - x_train_fold.shape:(123, 1088, 2), y_train_fold.shape:(123,), x_val_fold.shape:(41, 1088, 2), y_val_fold.shape:(41,)
----- stderr -----
2024-05-19 03:27:46 INFO [root] [<module>:8] - After slicing : x_train_sliced.shape:(615, 800, 2), y_train_sliced.shape:(615,), x_val_sliced.shape:(205, 800, 2), y_val_sliced.shape:(205,)
----- stderr -----
2024-05-19 03:27:46 INFO [root] [preprocess:104] - --Preprocessing--
----- stderr -----
2024-05-19 03:27:46 INFO [root] [preprocess:105] - [preprocess] preprocessing X_train.shape:(615, 800, 2), y_train.shape:(615,), X_test.shape:(205, 800, 2), y_test.shape:(205,)
----- stderr -----
2024-05-19 03:27:47 INFO [root] [preprocess:116] - [preprocess] after process X_train.shape:(640, 800, 2), y_train.shape:(615,), X_test.shape:(224, 800, 2), y_test.shape:(205,)
----- stderr -----
2024-05-19 03:27:47 INFO [root] [<module>:11] - After preprocess : X_train_task.shape:torch.Size([640, 800, 2]), y_train_task.shape:torch.Size([615]), X_test.shape:torch.Size([224, 800, 2]), y_test.shape:torch.Size([205])
----- stderr -----
2024-05-19 03:27:47 INFO [root] [<module>:16] - prop:{'batch': 32, 'lr': 0.01, 'nlayers': 2, 'emb_size': 64, 'nhead': 8, 'task_rate': 0.5, 'masking_ratio': 0.15, 'task_type': 'classification', 'lamb': 0.8, 'epochs': 250, 'ratio_highest_attention': 0.5, 'avg': 'macro', 'dropout': 0.01, 'nhid': 128, 'nhid_task': 128, 'nhid_tar': 128, 'dataset': 'Kailuan', 'accumulation_steps': 1, 'nclasses': 3, 'seq_len': 800, 'input_size': 2, 'device': device(type='cuda')}
----- stderr -----
2024-05-19 03:27:47 INFO [root] [<module>:18] - Initializing model...
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:32,seq_len:800,
----- stderr -----
2024-05-19 03:27:49 INFO [root] [<module>:20] - Model initialized...
----- stderr -----
2024-05-19 03:27:49 INFO [root] [<module>:22] - Training start...
----- stderr -----
2024-05-19 03:27:49 INFO [root] [training:318] - Using DataParallel for multi-GPU training
----- stderr -----
2024-05-19 03:27:49 INFO [root] [attention_sampled_masking_heuristic:147] - [attention_sampled_masking_heuristic], ratio_highest_attention:0.5, masking_ratio:0.15
----- stderr -----
2024-05-19 03:27:49 INFO [root] [attention_sampled_masking_heuristic:151] - [attention_sampled_masking_heuristic] instance_weights.shape:torch.Size([640, 800]),index.shape:torch.Size([640, 400])
----- stdout -----
---MultitaskTransformerModel init---
input_size:2, emb_size:64, batch:32,seq_len:800,
----- stderr -----
2024-05-19 03:27:50 INFO [root] [random_instance_masking:162] - [random_instance_masking]: X.shape:torch.Size([640, 800, 2]) ,indices.shape:(640, 120)
----- stderr -----
2024-05-19 03:27:53 INFO [root] [random_instance_masking:168] - [random_instance_masking]: X.shape:torch.Size([640, 800, 2]) ,boolean_indices.shape:(640, 800),boolean_indices_masked.shape:(640, 800, 2),boolean_indices_unmasked.shape:(640, 800, 2)
----- stderr -----
2024-05-19 03:27:53 INFO [root] [random_instance_masking:178] - [random_instance_masking] :X_train_tar.shape:torch.Size([640, 800, 2]), y_train_tar_masked.shape:torch.Size([640, 240]), y_train_tar_unmasked.shape:torch.Size([640, 1360])
----- stderr -----
2024-05-19 03:27:53 INFO [root] [multitask_train:222] - [multitask_train] accumulation_steps:1, X_train_tar.shape:torch.Size([640, 800, 2]), X_train_task.shape:torch.Size([640, 800, 2]), y_train_tar_masked.shape:torch.Size([640, 240]), y_train_tar_unmasked.shape:torch.Size([640, 1360]), y_train_task.shape:torch.Size([615])
----- stderr -----
2024-05-19 03:27:53 INFO [root] [multitask_train:234] - [multitask_train] batch:0, num_inst:32, start:0, end:32
----- stderr -----
2024-05-19 03:27:53 INFO [root] [multitask_train:239] - [multitask_train] batch:0, batched_input_tar.shape:torch.Size([32, 800, 2]), batched_input_task.shape:torch.Size([32, 800, 2]), batched_boolean_indices_masked.shape:(32, 800, 2), batched_boolean_indices_unmasked.shape:(32, 800, 2)
----- stderr -----
2024-05-19 03:27:56 INFO [root] [forward:118] - ---MultitaskTransformerModel forward---
----- stderr -----
2024-05-19 03:27:56 INFO [root] [forward:119] - [MultitaskTransformerModel] x.shape:torch.Size([11, 800, 2])
----- stderr -----
2024-05-19 03:27:56 INFO [root] [forward:118] - ---MultitaskTransformerModel forward---
----- stderr -----
2024-05-19 03:27:56 INFO [root] [forward:119] - [MultitaskTransformerModel] x.shape:torch.Size([11, 800, 2])
----- stderr -----
2024-05-19 03:27:56 INFO [root] [forward:118] - ---MultitaskTransformerModel forward---
----- stderr -----
2024-05-19 03:27:56 INFO [root] [forward:119] - [MultitaskTransformerModel] x.shape:torch.Size([10, 800, 2])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[22], line 23[0m
[1;32m     20[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mModel initialized...[39m[38;5;124m'[39m)
[1;32m     22[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining start...[39m[38;5;124m'[39m)
[0;32m---> 23[0m acc , rmse, mae  [38;5;241m=[39m [43mutils[49m[38;5;241;43m.[39;49m[43mtraining[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43mbest_model[49m[43m,[49m[43m [49m[43mbest_optimizer[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m[43mX_test[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m     24[0m logging[38;5;241m.[39minfo([38;5;124m'[39m[38;5;124mTraining complete...[39m[38;5;124m'[39m)
[1;32m     26[0m [38;5;28;01mif[39;00m prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mclassification[39m[38;5;124m'[39m:

File [0;32m/data4/gsprivate/TARnetWY/utils.py:331[0m, in [0;36mtraining[0;34m(model, optimizer, criterion_tar, criterion_task, best_model, best_optimizer, X_train_task, y_train_task, X_test, y_test, prop)[0m
[1;32m    325[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, prop[[38;5;124m'[39m[38;5;124mepochs[39m[38;5;124m'[39m] [38;5;241m+[39m [38;5;241m1[39m):
[1;32m    326[0m     
[1;32m    327[0m     [38;5;66;03m# 对训练数据进行随机实例掩码，准备重建任务的数据[39;00m
[1;32m    328[0m     X_train_tar, y_train_tar_masked, y_train_tar_unmasked, boolean_indices_masked, boolean_indices_unmasked [38;5;241m=[39m \
[1;32m    329[0m         random_instance_masking(X_train_task, prop[[38;5;124m'[39m[38;5;124mmasking_ratio[39m[38;5;124m'[39m], prop[[38;5;124m'[39m[38;5;124mratio_highest_attention[39m[38;5;124m'[39m], instance_weights)
[0;32m--> 331[0m     tar_loss_masked, tar_loss_unmasked, task_loss, instance_weights [38;5;241m=[39m [43mmultitask_train[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43mcriterion_task[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m
[1;32m    332[0m [43m                                        [49m[43mX_train_tar[49m[43m,[49m[43m [49m[43mX_train_task[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m[43my_train_task[49m[43m,[49m[43m [49m
[1;32m    333[0m [43m                                        [49m[43mboolean_indices_masked[49m[43m,[49m[43m [49m[43mboolean_indices_unmasked[49m[43m,[49m[43m [49m[43mprop[49m[43m)[49m
[1;32m    335[0m     tar_loss_masked_arr[38;5;241m.[39mappend(tar_loss_masked)
[1;32m    336[0m     tar_loss_unmasked_arr[38;5;241m.[39mappend(tar_loss_unmasked)

File [0;32m/data4/gsprivate/TARnetWY/utils.py:241[0m, in [0;36mmultitask_train[0;34m(model, criterion_tar, criterion_task, optimizer, X_train_tar, X_train_task, y_train_tar_masked, y_train_tar_unmasked, y_train_task, boolean_indices_masked, boolean_indices_unmasked, prop)[0m
[1;32m    238[0m batched_boolean_indices_unmasked [38;5;241m=[39m boolean_indices_unmasked[start:end]
[1;32m    239[0m logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[multitask_train] batch:[39m[38;5;132;01m{[39;00mi[38;5;132;01m}[39;00m[38;5;124m, batched_input_tar.shape:[39m[38;5;132;01m{[39;00mbatched_input_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_input_task.shape:[39m[38;5;132;01m{[39;00mbatched_input_task[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_masked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_masked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m, batched_boolean_indices_unmasked.shape:[39m[38;5;132;01m{[39;00mbatched_boolean_indices_unmasked[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m--> 241[0m loss_tar_masked, loss_tar_unmasked [38;5;241m=[39m [43mcompute_tar_loss[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mprop[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdevice[39;49m[38;5;124;43m'[39;49m[43m][49m[43m,[49m[43m [49m[43mcriterion_tar[49m[43m,[49m[43m [49m[43my_train_tar_masked[49m[43m,[49m[43m [49m[43my_train_tar_unmasked[49m[43m,[49m[43m [49m
[1;32m    242[0m [43m    [49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_masked[49m[43m,[49m[43m [49m[43mbatched_boolean_indices_unmasked[49m[43m,[49m[43m [49m[43mnum_inst[49m[43m,[49m[43m [49m[43mstart[49m[43m)[49m
[1;32m    244[0m attn, loss_task [38;5;241m=[39m compute_task_loss(prop[[38;5;124m'[39m[38;5;124mnclasses[39m[38;5;124m'[39m], model, prop[[38;5;124m'[39m[38;5;124mdevice[39m[38;5;124m'[39m], criterion_task, y_train_task, 
[1;32m    245[0m     batched_input_task, prop[[38;5;124m'[39m[38;5;124mtask_type[39m[38;5;124m'[39m], num_inst, start)
[1;32m    247[0m total_loss_tar_masked [38;5;241m+[39m[38;5;241m=[39m loss_tar_masked[38;5;241m.[39mitem() 

File [0;32m/data4/gsprivate/TARnetWY/utils.py:186[0m, in [0;36mcompute_tar_loss[0;34m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start)[0m
[1;32m    183[0m [38;5;28;01mdef[39;00m [38;5;21mcompute_tar_loss[39m(model, device, criterion_tar, y_train_tar_masked, y_train_tar_unmasked, batched_input_tar, \
[1;32m    184[0m                     batched_boolean_indices_masked, batched_boolean_indices_unmasked, num_inst, start):
[1;32m    185[0m     model[38;5;241m.[39mtrain()
[0;32m--> 186[0m     out_tar [38;5;241m=[39m [43mmodel[49m[43m([49m[43mtorch[49m[38;5;241;43m.[39;49m[43mas_tensor[49m[43m([49m[43mbatched_input_tar[49m[43m,[49m[43m [49m[43mdevice[49m[43m [49m[38;5;241;43m=[39;49m[43m [49m[43mdevice[49m[43m)[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mreconstruction[39;49m[38;5;124;43m'[39;49m[43m)[49m[[38;5;241m0[39m]
[1;32m    187[0m     logging[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124m[compute_tar_loss] out_tar.shape:[39m[38;5;132;01m{[39;00mout_tar[38;5;241m.[39mshape[38;5;132;01m}[39;00m[38;5;124m"[39m)
[1;32m    188[0m     out_tar_masked [38;5;241m=[39m torch[38;5;241m.[39mas_tensor(out_tar[torch[38;5;241m.[39mas_tensor(batched_boolean_indices_masked)][38;5;241m.[39mreshape(out_tar[38;5;241m.[39mshape[[38;5;241m0[39m], [38;5;241m-[39m[38;5;241m1[39m), device [38;5;241m=[39m device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py:1194[0m, in [0;36mModule._call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1190[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[1;32m   1191[0m [38;5;66;03m# this function, and just call forward.[39;00m
[1;32m   1192[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[1;32m   1193[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[0;32m-> 1194[0m     [38;5;28;01mreturn[39;00m [43mforward_call[49m[43m([49m[38;5;241;43m*[39;49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m   1195[0m [38;5;66;03m# Do not call functions when jit is used[39;00m
[1;32m   1196[0m full_backward_hooks, non_full_backward_hooks [38;5;241m=[39m [], []

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:171[0m, in [0;36mDataParallel.forward[0;34m(self, *inputs, **kwargs)[0m
[1;32m    169[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mmodule([38;5;241m*[39minputs[[38;5;241m0[39m], [38;5;241m*[39m[38;5;241m*[39mkwargs[[38;5;241m0[39m])
[1;32m    170[0m replicas [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mreplicate([38;5;28mself[39m[38;5;241m.[39mmodule, [38;5;28mself[39m[38;5;241m.[39mdevice_ids[:[38;5;28mlen[39m(inputs)])
[0;32m--> 171[0m outputs [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mparallel_apply[49m[43m([49m[43mreplicas[49m[43m,[49m[43m [49m[43minputs[49m[43m,[49m[43m [49m[43mkwargs[49m[43m)[49m
[1;32m    172[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mgather(outputs, [38;5;28mself[39m[38;5;241m.[39moutput_device)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:181[0m, in [0;36mDataParallel.parallel_apply[0;34m(self, replicas, inputs, kwargs)[0m
[1;32m    180[0m [38;5;28;01mdef[39;00m [38;5;21mparallel_apply[39m([38;5;28mself[39m, replicas, inputs, kwargs):
[0;32m--> 181[0m     [38;5;28;01mreturn[39;00m [43mparallel_apply[49m[43m([49m[43mreplicas[49m[43m,[49m[43m [49m[43minputs[49m[43m,[49m[43m [49m[43mkwargs[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdevice_ids[49m[43m[[49m[43m:[49m[38;5;28;43mlen[39;49m[43m([49m[43mreplicas[49m[43m)[49m[43m][49m[43m)[49m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:89[0m, in [0;36mparallel_apply[0;34m(modules, inputs, kwargs_tup, devices)[0m
[1;32m     87[0m     output [38;5;241m=[39m results[i]
[1;32m     88[0m     [38;5;28;01mif[39;00m [38;5;28misinstance[39m(output, ExceptionWrapper):
[0;32m---> 89[0m         [43moutput[49m[38;5;241;43m.[39;49m[43mreraise[49m[43m([49m[43m)[49m
[1;32m     90[0m     outputs[38;5;241m.[39mappend(output)
[1;32m     91[0m [38;5;28;01mreturn[39;00m outputs

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/_utils.py:543[0m, in [0;36mExceptionWrapper.reraise[0;34m(self)[0m
[1;32m    539[0m [38;5;28;01mexcept[39;00m [38;5;167;01mTypeError[39;00m:
[1;32m    540[0m     [38;5;66;03m# If the exception takes multiple arguments, don't try to[39;00m
[1;32m    541[0m     [38;5;66;03m# instantiate since we don't know how to[39;00m
[1;32m    542[0m     [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m(msg) [38;5;28;01mfrom[39;00m [38;5;28;01mNone[39;00m
[0;32m--> 543[0m [38;5;28;01mraise[39;00m exception

[0;31mRuntimeError[0m: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data4/gsprivate/TARnetWY/multitask_transformer_class.py", line 120, in forward
    x = self.trunk_net(x.permute(1, 0, 2))
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: running_mean should contain 11 elements not 32


[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:34:22.875194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:34:25.772768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import os
# from aeon.datasets.tsc_data_lists import multivariate_equal_length
import pandas as pd
import numpy as np
from sklearn import preprocessing
import sklearn
from tensorflow import keras
import tensorflow as tf
import numpy as np
import time 
# from utils import geng
import logconfig
import geng
import torch
import logging
import torch.distributed as dist
# # 修改一个已存在的环境变量
# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']
# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']
# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']
# 使用设置好的环境变量
os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'
# 初始化分布式训练
dist.init_process_group(backend='nccl')

logname = "slice_ws800_ss64_bs64(as1)"
logconfig.setup_logging(dir="./",name=logname)
logging.info(f"PATH:{os.environ['PATH']}\nCUDA_HOME:{os.environ['CUDA_HOME']}")
# dataset_name = "170Kailuan-relu-5"
window_size = 800  # length of each segment
step_size = 64     # step size between segments
accumulation_steps = 1
------------------

----- stderr -----
2024-05-19 03:34:22.875194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----- stderr -----
2024-05-19 03:34:25.772768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
----- stderr -----
/data4/conda_envs/g2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
Cell [0;32mIn[1], line 24[0m
[1;32m     22[0m os[38;5;241m.[39menviron[[38;5;124m'[39m[38;5;124mCUDA_VISIBLE_DEVICES[39m[38;5;124m'[39m] [38;5;241m=[39m [38;5;124m'[39m[38;5;124m5,6,7[39m[38;5;124m'[39m
[1;32m     23[0m [38;5;66;03m# 初始化分布式训练[39;00m
[0;32m---> 24[0m [43mdist[49m[38;5;241;43m.[39;49m[43minit_process_group[49m[43m([49m[43mbackend[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mnccl[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m     26[0m logname [38;5;241m=[39m [38;5;124m"[39m[38;5;124mslice_ws800_ss64_bs64(as1)[39m[38;5;124m"[39m
[1;32m     27[0m logconfig[38;5;241m.[39msetup_logging([38;5;28mdir[39m[38;5;241m=[39m[38;5;124m"[39m[38;5;124m./[39m[38;5;124m"[39m,name[38;5;241m=[39mlogname)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:754[0m, in [0;36minit_process_group[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)[0m
[1;32m    750[0m [38;5;28;01mif[39;00m store [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[1;32m    751[0m     rendezvous_iterator [38;5;241m=[39m rendezvous(
[1;32m    752[0m         init_method, rank, world_size, timeout[38;5;241m=[39mtimeout
[1;32m    753[0m     )
[0;32m--> 754[0m     store, rank, world_size [38;5;241m=[39m [38;5;28;43mnext[39;49m[43m([49m[43mrendezvous_iterator[49m[43m)[49m
[1;32m    755[0m     store[38;5;241m.[39mset_timeout(timeout)
[1;32m    757[0m     [38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by[39;00m
[1;32m    758[0m     [38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/rendezvous.py:236[0m, in [0;36m_env_rendezvous_handler[0;34m(url, timeout, **kwargs)[0m
[1;32m    234[0m     rank [38;5;241m=[39m [38;5;28mint[39m(query_dict[[38;5;124m"[39m[38;5;124mrank[39m[38;5;124m"[39m])
[1;32m    235[0m [38;5;28;01melse[39;00m:
[0;32m--> 236[0m     rank [38;5;241m=[39m [38;5;28mint[39m([43m_get_env_or_raise[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mRANK[39;49m[38;5;124;43m"[39;49m[43m)[49m)
[1;32m    238[0m [38;5;28;01mif[39;00m [38;5;124m"[39m[38;5;124mworld_size[39m[38;5;124m"[39m [38;5;129;01min[39;00m query_dict:
[1;32m    239[0m     world_size [38;5;241m=[39m [38;5;28mint[39m(query_dict[[38;5;124m"[39m[38;5;124mworld_size[39m[38;5;124m"[39m])

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/rendezvous.py:221[0m, in [0;36m_env_rendezvous_handler.<locals>._get_env_or_raise[0;34m(env_var)[0m
[1;32m    219[0m env_val [38;5;241m=[39m os[38;5;241m.[39menviron[38;5;241m.[39mget(env_var, [38;5;28;01mNone[39;00m)
[1;32m    220[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m env_val:
[0;32m--> 221[0m     [38;5;28;01mraise[39;00m _env_error(env_var)
[1;32m    222[0m [38;5;28;01melse[39;00m:
[1;32m    223[0m     [38;5;28;01mreturn[39;00m env_val

[0;31mValueError[0m: Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:36:58.468459: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:37:00.445543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import os
# from aeon.datasets.tsc_data_lists import multivariate_equal_length
import pandas as pd
import numpy as np
from sklearn import preprocessing
import sklearn
from tensorflow import keras
import tensorflow as tf
import numpy as np
import time 
# from utils import geng
import logconfig
import geng
import torch
import logging
import torch.distributed as dist
# # 修改一个已存在的环境变量
# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']
# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']
# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']
# 使用设置好的环境变量
os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'
os.environ['RANK'] = '0'  # 当前进程的 rank
os.environ['WORLD_SIZE'] = '3'  # 总共参与训练的进程数
# 初始化分布式训练
dist.init_process_group(backend='nccl')

logname = "slice_ws800_ss64_bs64(as1)"
logconfig.setup_logging(dir="./",name=logname)
logging.info(f"PATH:{os.environ['PATH']}\nCUDA_HOME:{os.environ['CUDA_HOME']}")
# dataset_name = "170Kailuan-relu-5"
window_size = 800  # length of each segment
step_size = 64     # step size between segments
accumulation_steps = 1
------------------

----- stderr -----
2024-05-19 03:36:58.468459: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----- stderr -----
2024-05-19 03:37:00.445543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
----- stderr -----
/data4/conda_envs/g2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
Cell [0;32mIn[1], line 26[0m
[1;32m     24[0m os[38;5;241m.[39menviron[[38;5;124m'[39m[38;5;124mWORLD_SIZE[39m[38;5;124m'[39m] [38;5;241m=[39m [38;5;124m'[39m[38;5;124m3[39m[38;5;124m'[39m  [38;5;66;03m# 总共参与训练的进程数[39;00m
[1;32m     25[0m [38;5;66;03m# 初始化分布式训练[39;00m
[0;32m---> 26[0m [43mdist[49m[38;5;241;43m.[39;49m[43minit_process_group[49m[43m([49m[43mbackend[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mnccl[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m     28[0m logname [38;5;241m=[39m [38;5;124m"[39m[38;5;124mslice_ws800_ss64_bs64(as1)[39m[38;5;124m"[39m
[1;32m     29[0m logconfig[38;5;241m.[39msetup_logging([38;5;28mdir[39m[38;5;241m=[39m[38;5;124m"[39m[38;5;124m./[39m[38;5;124m"[39m,name[38;5;241m=[39mlogname)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:754[0m, in [0;36minit_process_group[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)[0m
[1;32m    750[0m [38;5;28;01mif[39;00m store [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[1;32m    751[0m     rendezvous_iterator [38;5;241m=[39m rendezvous(
[1;32m    752[0m         init_method, rank, world_size, timeout[38;5;241m=[39mtimeout
[1;32m    753[0m     )
[0;32m--> 754[0m     store, rank, world_size [38;5;241m=[39m [38;5;28;43mnext[39;49m[43m([49m[43mrendezvous_iterator[49m[43m)[49m
[1;32m    755[0m     store[38;5;241m.[39mset_timeout(timeout)
[1;32m    757[0m     [38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by[39;00m
[1;32m    758[0m     [38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/rendezvous.py:243[0m, in [0;36m_env_rendezvous_handler[0;34m(url, timeout, **kwargs)[0m
[1;32m    240[0m [38;5;28;01melse[39;00m:
[1;32m    241[0m     world_size [38;5;241m=[39m [38;5;28mint[39m(_get_env_or_raise([38;5;124m"[39m[38;5;124mWORLD_SIZE[39m[38;5;124m"[39m))
[0;32m--> 243[0m master_addr [38;5;241m=[39m [43m_get_env_or_raise[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mMASTER_ADDR[39;49m[38;5;124;43m"[39;49m[43m)[49m
[1;32m    244[0m master_port [38;5;241m=[39m [38;5;28mint[39m(_get_env_or_raise([38;5;124m"[39m[38;5;124mMASTER_PORT[39m[38;5;124m"[39m))
[1;32m    246[0m store [38;5;241m=[39m _create_c10d_store(master_addr, master_port, rank, world_size, timeout)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/rendezvous.py:221[0m, in [0;36m_env_rendezvous_handler.<locals>._get_env_or_raise[0;34m(env_var)[0m
[1;32m    219[0m env_val [38;5;241m=[39m os[38;5;241m.[39menviron[38;5;241m.[39mget(env_var, [38;5;28;01mNone[39;00m)
[1;32m    220[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m env_val:
[0;32m--> 221[0m     [38;5;28;01mraise[39;00m _env_error(env_var)
[1;32m    222[0m [38;5;28;01melse[39;00m:
[1;32m    223[0m     [38;5;28;01mreturn[39;00m env_val

[0;31mValueError[0m: Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_ADDR expected, but not set

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:40:32.351681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:40:33.859731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Writing 18031715 bytes to multi-geng.nbconvert.ipynb
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 03:48:54.234171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 03:48:56.569366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:12355 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import os
# from aeon.datasets.tsc_data_lists import multivariate_equal_length
import pandas as pd
import numpy as np
from sklearn import preprocessing
import sklearn
from tensorflow import keras
import tensorflow as tf
import numpy as np
import time 
# from utils import geng
import logconfig
import geng
import torch
import logging
import torch.distributed as dist
# # 修改一个已存在的环境变量
# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']
# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']
# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']
# 使用设置好的环境变量
os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'
# 设置分布式训练所需的环境变量
os.environ['MASTER_ADDR'] = 'localhost'  # 主节点地址
os.environ['MASTER_PORT'] = '12355'      # 主节点端口号
os.environ['RANK'] = '0'                # 当前进程的 rank
os.environ['WORLD_SIZE'] = '3'          # 总共参与训练的进程数
# 初始化分布式训练
dist.init_process_group(backend='nccl')

logname = "slice_ws800_ss64_bs64(as1)"
logconfig.setup_logging(dir="./",name=logname)
logging.info(f"PATH:{os.environ['PATH']}\nCUDA_HOME:{os.environ['CUDA_HOME']}")
# dataset_name = "170Kailuan-relu-5"
window_size = 800  # length of each segment
step_size = 64     # step size between segments
accumulation_steps = 1
------------------

----- stderr -----
2024-05-19 03:48:54.234171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----- stderr -----
2024-05-19 03:48:56.569366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
----- stderr -----
/data4/conda_envs/g2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
----- stderr -----
[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:12355 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[1], line 29[0m
[1;32m     27[0m os[38;5;241m.[39menviron[[38;5;124m'[39m[38;5;124mWORLD_SIZE[39m[38;5;124m'[39m] [38;5;241m=[39m [38;5;124m'[39m[38;5;124m3[39m[38;5;124m'[39m          [38;5;66;03m# 总共参与训练的进程数[39;00m
[1;32m     28[0m [38;5;66;03m# 初始化分布式训练[39;00m
[0;32m---> 29[0m [43mdist[49m[38;5;241;43m.[39;49m[43minit_process_group[49m[43m([49m[43mbackend[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mnccl[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m     31[0m logname [38;5;241m=[39m [38;5;124m"[39m[38;5;124mslice_ws800_ss64_bs64(as1)[39m[38;5;124m"[39m
[1;32m     32[0m logconfig[38;5;241m.[39msetup_logging([38;5;28mdir[39m[38;5;241m=[39m[38;5;124m"[39m[38;5;124m./[39m[38;5;124m"[39m,name[38;5;241m=[39mlogname)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:754[0m, in [0;36minit_process_group[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)[0m
[1;32m    750[0m [38;5;28;01mif[39;00m store [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[1;32m    751[0m     rendezvous_iterator [38;5;241m=[39m rendezvous(
[1;32m    752[0m         init_method, rank, world_size, timeout[38;5;241m=[39mtimeout
[1;32m    753[0m     )
[0;32m--> 754[0m     store, rank, world_size [38;5;241m=[39m [38;5;28;43mnext[39;49m[43m([49m[43mrendezvous_iterator[49m[43m)[49m
[1;32m    755[0m     store[38;5;241m.[39mset_timeout(timeout)
[1;32m    757[0m     [38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by[39;00m
[1;32m    758[0m     [38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/rendezvous.py:246[0m, in [0;36m_env_rendezvous_handler[0;34m(url, timeout, **kwargs)[0m
[1;32m    243[0m master_addr [38;5;241m=[39m _get_env_or_raise([38;5;124m"[39m[38;5;124mMASTER_ADDR[39m[38;5;124m"[39m)
[1;32m    244[0m master_port [38;5;241m=[39m [38;5;28mint[39m(_get_env_or_raise([38;5;124m"[39m[38;5;124mMASTER_PORT[39m[38;5;124m"[39m))
[0;32m--> 246[0m store [38;5;241m=[39m [43m_create_c10d_store[49m[43m([49m[43mmaster_addr[49m[43m,[49m[43m [49m[43mmaster_port[49m[43m,[49m[43m [49m[43mrank[49m[43m,[49m[43m [49m[43mworld_size[49m[43m,[49m[43m [49m[43mtimeout[49m[43m)[49m
[1;32m    248[0m [38;5;28;01myield[39;00m (store, rank, world_size)
[1;32m    250[0m [38;5;66;03m# If this configuration is invalidated, there is nothing we can do about it[39;00m

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/rendezvous.py:177[0m, in [0;36m_create_c10d_store[0;34m(hostname, port, rank, world_size, timeout)[0m
[1;32m    175[0m [38;5;28;01melse[39;00m:
[1;32m    176[0m     start_daemon [38;5;241m=[39m rank [38;5;241m==[39m [38;5;241m0[39m
[0;32m--> 177[0m     [38;5;28;01mreturn[39;00m [43mTCPStore[49m[43m([49m
[1;32m    178[0m [43m        [49m[43mhostname[49m[43m,[49m[43m [49m[43mport[49m[43m,[49m[43m [49m[43mworld_size[49m[43m,[49m[43m [49m[43mstart_daemon[49m[43m,[49m[43m [49m[43mtimeout[49m[43m,[49m[43m [49m[43mmulti_tenant[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m
[1;32m    179[0m [43m    [49m[43m)[49m

[0;31mRuntimeError[0m: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:12355 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).

Traceback (most recent call last):
  File "/data4/conda_envs/g2/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/application.py", line 280, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/traitlets/config/application.py", line 992, in launch_instance
    app.start()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/data4/conda_envs/g2/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/data4/conda_envs/g2/lib/python3.8/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import os
# from aeon.datasets.tsc_data_lists import multivariate_equal_length
import pandas as pd
import numpy as np
from sklearn import preprocessing
import sklearn
from tensorflow import keras
import tensorflow as tf
import numpy as np
import time 
# from utils import geng
import logconfig
import geng
import torch
import logging
import torch.distributed as dist
# # 修改一个已存在的环境变量
# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']
# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']
# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']
# 使用设置好的环境变量
os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'
# 设置分布式训练所需的环境变量
os.environ['MASTER_ADDR'] = 'localhost'  # 主节点地址
os.environ['MASTER_PORT'] = '12355'      # 主节点端口号
os.environ['RANK'] = '0'                # 当前进程的 rank
os.environ['WORLD_SIZE'] = '3'          # 总共参与训练的进程数
# 初始化分布式训练
dist.init_process_group(backend='nccl')

logname = "slice_ws800_ss64_bs64(as1)"
logconfig.setup_logging(dir="./",name=logname)
logging.info(f"PATH:{os.environ['PATH']}\nCUDA_HOME:{os.environ['CUDA_HOME']}")
# dataset_name = "170Kailuan-relu-5"
window_size = 800  # length of each segment
step_size = 64     # step size between segments
accumulation_steps = 1
------------------

----- stderr -----
2024-05-19 03:40:32.351681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----- stderr -----
2024-05-19 03:40:33.859731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
----- stderr -----
/data4/conda_envs/g2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[1], line 29[0m
[1;32m     27[0m os[38;5;241m.[39menviron[[38;5;124m'[39m[38;5;124mWORLD_SIZE[39m[38;5;124m'[39m] [38;5;241m=[39m [38;5;124m'[39m[38;5;124m3[39m[38;5;124m'[39m          [38;5;66;03m# 总共参与训练的进程数[39;00m
[1;32m     28[0m [38;5;66;03m# 初始化分布式训练[39;00m
[0;32m---> 29[0m [43mdist[49m[38;5;241;43m.[39;49m[43minit_process_group[49m[43m([49m[43mbackend[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mnccl[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m     31[0m logname [38;5;241m=[39m [38;5;124m"[39m[38;5;124mslice_ws800_ss64_bs64(as1)[39m[38;5;124m"[39m
[1;32m     32[0m logconfig[38;5;241m.[39msetup_logging([38;5;28mdir[39m[38;5;241m=[39m[38;5;124m"[39m[38;5;124m./[39m[38;5;124m"[39m,name[38;5;241m=[39mlogname)

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:786[0m, in [0;36minit_process_group[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)[0m
[1;32m    782[0m     barrier()
[1;32m    783[0m [38;5;28;01melse[39;00m:
[1;32m    784[0m     [38;5;66;03m# Use store based barrier here since barrier() used a bunch of[39;00m
[1;32m    785[0m     [38;5;66;03m# default devices and messes up NCCL internal state.[39;00m
[0;32m--> 786[0m     [43m_store_based_barrier[49m[43m([49m[43mrank[49m[43m,[49m[43m [49m[43mstore[49m[43m,[49m[43m [49m[43mtimeout[49m[43m)[49m
[1;32m    787[0m     [38;5;66;03m# Set sequence numbers for gloo and nccl process groups.[39;00m
[1;32m    788[0m     [38;5;28;01mif[39;00m get_backend(default_pg) [38;5;129;01min[39;00m [Backend[38;5;241m.[39mGLOO, Backend[38;5;241m.[39mNCCL]:

File [0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:346[0m, in [0;36m_store_based_barrier[0;34m(rank, store, timeout)[0m
[1;32m    343[0m         log_time [38;5;241m=[39m time[38;5;241m.[39mtime()
[1;32m    345[0m     [38;5;28;01mif[39;00m timedelta(seconds[38;5;241m=[39m(time[38;5;241m.[39mtime() [38;5;241m-[39m start)) [38;5;241m>[39m timeout:
[0;32m--> 346[0m         [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m(
[1;32m    347[0m             [38;5;124m"[39m[38;5;124mTimed out initializing process group in store based barrier on [39m[38;5;124m"[39m
[1;32m    348[0m             [38;5;124m"[39m[38;5;124mrank: [39m[38;5;132;01m{}[39;00m[38;5;124m, for key: [39m[38;5;132;01m{}[39;00m[38;5;124m (world_size=[39m[38;5;132;01m{}[39;00m[38;5;124m, worker_count=[39m[38;5;132;01m{}[39;00m[38;5;124m, timeout=[39m[38;5;132;01m{}[39;00m[38;5;124m)[39m[38;5;124m"[39m[38;5;241m.[39mformat(
[1;32m    349[0m                 rank, store_key, world_size, worker_count, timeout
[1;32m    350[0m             )
[1;32m    351[0m         )
[1;32m    353[0m logger[38;5;241m.[39minfo(
[1;32m    354[0m     [38;5;124mf[39m[38;5;124m"[39m[38;5;124mRank [39m[38;5;132;01m{[39;00mrank[38;5;132;01m}[39;00m[38;5;124m: Completed store-based barrier for key:[39m[38;5;132;01m{[39;00mstore_key[38;5;132;01m}[39;00m[38;5;124m with [39m[38;5;132;01m{[39;00mworld_size[38;5;132;01m}[39;00m[38;5;124m nodes.[39m[38;5;124m"[39m
[1;32m    355[0m )

[0;31mRuntimeError[0m: Timed out initializing process group in store based barrier on rank: 0, for key: store_based_barrier_key:1 (world_size=3, worker_count=1, timeout=0:30:00)

[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 08:05:52.257424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 08:05:55.547080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[NbConvertApp] Converting notebook ./multi-geng.ipynb to notebook
2024-05-19 08:31:55.902233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-19 08:31:56.757804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
